# Day 29-1 | 架構演進的協奏曲：結合絞殺者模式與 BFF 實現單體系統的優雅轉身

在業界，我們手中握有的從來都不是一張白紙。多數時候，我們面對的是一個已經運行多年、承載著核心業務、程式碼盤根錯節的「單體系統 (Monolith)」。它就像一座老舊但仍在運作的城市，我們不能直接將它夷為平地再蓋一座新城，因為市民（也就是我們的用戶和業務）還在裡面生活。

Jr.工程師看到的是混亂，他們的第一反應是：「天啊，我們開始重構吧！(喜」

但對於有經驗的人員來說則是品鑑得夠多了，快端下去罷。

這樣的「大爆炸式重寫」(Big Bang Rewrite) 專案，最終成為失控的花火 - 開頭絢爛奪目，結局卻是一片狼藉，耗費了數百萬美金與團隊數年的心血，最終交付的系統甚至不如舊的穩定。

我們接下來要討論的，是一種更成熟、更優雅，如同指揮家引領一場複雜交響樂的藝術——系統演進 (System Evolution)。這場演進的核心，就是我們今天的主題：絞殺者模式 (Strangler Fig Pattern) 與 BFF (Backend for Frontend) 的協奏曲。

我們將一同瞧瞧一種強大且低風險的架構遷移模式——絞殺者無花果模式 (Strangler Fig Pattern)。這個模式由 Martin Fowler 提出，旨在透過逐步、增量地用新的微服務替換舊單體應用的特定功能，來實現從單體到微服務的平滑過渡。

絞殺者模式的核心是避免「大爆炸式」的重構所帶來的巨大風險和業務中斷。透過在單體應用外圍建立一個新的「外牆」（通常是 API Gateway），我們可以攔截請求，並將對特定功能的請求路由到新開發的微服務，而其他請求則繼續由舊單體處理。隨著時間推移，新服務會逐漸「包裹」並最終「絞殺」掉舊系統 。我們將學習如何利用 AWS API Gateway 作為代理，來實現這種漸進式的遷移。

前端的後端 (Backend for Frontends， BFF)是一種在微服務架構中極為常見的優化模式。BFF 模式主張為每種不同的前端客戶端（如網頁、iOS App、Android App）建立一個專屬的、輕量級的後端服務。這個 BFF 的唯一職責，就是從下游的多個通用微服務中聚合、裁剪和格式化數據，**為前端體驗量身打造後端 API**。

BFF 模式解決了通用 API「一體適用，處處不適」的窘境。行動端需要精簡的數據以節省流量，而網頁端可能需要豐富的數據來呈現複雜的 UI。透過為每個前端提供一個專門的「翻譯官」和「數據聚合器」，極大地簡化了前端開發，並優化了終端使用者體驗 。

前奏結束，讓我們開啟第一樂章。(於此感謝兩廳院系統與台北市立管弦樂團所帶來的靈感，他們為了推廣交響樂，演出的費用低到不捨)

## 第一樂章：哲學篇 - 為何選擇演進，而非重建？

在我們探討任何具體的 AWS 服務或設計模式之前，必須先在思想上達成一個共識：**我們的首要職責，不是建造閃亮的技術聖殿，而是 `確保承載業務的航船能在不斷變化的洶湧波濤中，安全、持續地航行`。**

「大爆炸式重寫」看似能打造一艘全新的、完美的戰艦，但其真相是，我們正在要求所有乘客（業務）和船員（團隊）在汪洋大海中，直接從舊船跳上那艘還在建造、未經試航的新船。稍有不慎，便是船毀人亡。

因此，現代雲端架構師的核心技藝，是引導 (Guiding)，而非革命 (Revolution)。我們是指揮家，協調新舊樂器，讓樂曲平滑過渡；我們是園丁，悉心培育，讓花園生機盎然。

### 第一曲：《卡門》- 重寫的致命誘惑

首先，我們必須誠實地面對並解構「重寫」這個選項為何如此誘人，尤其對工程師而言。

比才的創作《卡門》以其熱情、奔放的旋律描繪了一段致命的吸引力、激情、誘惑，但對比其故事的結局卻是悲劇性的，某種程度上也算相當早期的乖乖牌被黃毛/綠茶給搞砸人生的故事了吧。

這恰如其分地隱喻了「從零開始重寫」對工程師那難以抗拒的誘惑 - 在否定這個選項前，我們必須誠實地解構其吸引力的來源。

1. 技術純粹主義的渴望

**打造一個「完美」架構的理想主義衝動。**

我們的內心深處，往往住著一位追求秩序與完美的理想主義者，面對充滿妥協與歷史痕跡的舊系統，一種「格式化」一切的衝動油然而生。這是一種對「秩序」與「完美」的本能追求，深植於優秀工程師的基因中。

面對充滿歷史債務、妥協與「髒代碼」的舊系統，我們內心會升起一種強烈的「格式化」衝動。我們渴望在一個完美的「綠地 (Greenfield)」上，使用最前沿的技術棧、最優雅的設計模式，不受任何歷史束縛，去打造一座完美的技術聖殿。

但我們真的完全理解那個運行了十年的單體系統 (Monolith) 裡所有的「隱藏規則」嗎？那些沒有寫在文件裡，只存在於某個已離職的工程師腦中的商業邏輯，一旦遺漏，後果是災難性的。(經典案例:"//該死，他怎麼跑起來的")

**還記得 Day 2-2 我們分析投資交易系統時的嚴苛需求嗎？**系統要求 API 響應時間 < 100ms、支援 2000+ 併發查詢、強一致性的數據保證<Day 2-2 | 需求確認 × 系統設計起點(二)：領域邊界與基礎需求確認>。面對這樣的要求，技術純粹主義會讓我們想用最新的技術棧重寫——但這正是最危險的誘惑，因為我們很容易忽略那些隱藏在舊系統深處的「隱藏規則」。

我們要謹記，

**`商業系統的本質是「演化」而非「創造」。**

它是 **`有機的`**、混亂的，是為了在真實世界生存而充滿了妥協。對「絕對純淨」的追求，本身就是一種脫離現實的教條主義。

2. 「理解不如重寫」的錯覺

**這是一種常見的認知捷徑。**

這是一種認知偏誤。理解一個龐大而複雜的舊系統，需要的是考古學家和偵探般的極大的耐心去挖掘、梳理、解讀那些已被遺忘的商業邏輯，抽絲剝繭的過程盤根錯節充滿挫折，且進展緩慢；而重寫一個新系統，給人的感覺是上帝般的創世快感。

前者是被動的、充滿挫折的挖掘過程；後者是主動的、充滿成就感的建設過程 - 人性自然會傾向於後者。然而，這種錯覺的代價是，我們放棄了挖掘過程中那些不起眼卻無價的寶藏——那些隱藏在舊代碼背後的、血淚換來的業務邏輯。

**Day 3 和 Day 4 告訴我們理解系統的真正難度。**在抽象建模中，我們學到系統需要從四個維度理解：概念建模回答系統的本質是什麼、行為建模回答系統會做什麼、資料建模回答系統記住什麼、架構建模回答系統如何組織<Day 3 | 需求萃取方法論-抽象建模(Abstract Modeling)>。**Day 4 的 Portfolio 聚合案例**更揭示了業務不變式的複雜性：總資產價值必須等於所有持倉價值加上現金餘額、任何交易都不能導致資金為負、風險敞口不能超過預設限額<Day 4 | 用 DDD 建構業務邏輯：從用例到聚合設計>。這些隱藏在代碼中的業務規則，在重寫時很容易被遺漏，導致災難性後果。

**而 Day 10 的快取策略更揭示了系統知識的時間維度。**不同類型的數據有著不同的訪問模式和生命週期特性：熱數據需要極高訪問頻率、溫數據需要中等訪問頻率、冷數據則可以接受較低的訪問效率<Day 10 | 快取策略的哲學>。這種對數據生命週期的深刻理解，是無法通過簡單的「重寫」來獲得的，它需要對業務的長期觀察和實踐積累。

有一個老系統笑話是這樣子的

> 古老的系統就像是遺跡
>
> 一但我們像蘿拉或是印第安那瓊斯般，但凡拿走了遺跡中一點"文物"
>
> 我們都會召喚出遺跡守護者 - 資深工程師、負責業務甚至是老闆 - 追殺我們直到文物被歸還原處，又或是遺跡徹底崩塌。

3. 英雄主義的劇本

**我們的產業文化頌揚創新與顛覆。**

推翻一個陳舊的系統，建立一個全新的秩序，這個故事本身就充滿了英雄色彩。主導一次重大的重寫專案，往往被視為一次展現技術遠見與領導力的絕佳機會，能為個人履歷添上濃墨重彩的一筆。

但漫長的重寫專案是團隊士氣的墳墓。當我們看不到盡頭、當壓力與日俱增，可能那個提倡重寫的人寫不動了、跑路離職了，後面又要花更多的成本來找人處理，成功達成了一個職位創造了 3 個機會的 GDP 與就業率雙雙成長指標。

**Day 12 的版本控制策略中**，我們討論了敏捷思維與英雄主義的衝突：優秀的工程師往往追求秩序與完美，他們希望能夠成為全場焦點，而不僅僅是默默傳球的配角<Day 12 | 版本控制策略 × Git Flow × Lint>。這種心理正是「英雄主義劇本」的源頭——我們都想成為那個「拯救系統」的英雄。

**但 Day 6 的成本管控告訴我們殘酷的現實。**系統開發和維護需要持續的人力投入和資金成本，包括工程師薪資、基礎設施費用、以及長期的維運開銷<Day 6 | Trade-off 成本管控藝術>。重寫專案的真實代價，不僅是技術投入，更是人力的長期消耗和機會成本。那個「跑路離職」的提倡者，留下的是團隊的疲憊和未完成的承諾。

真正的優越，不是體現在用巨大的資源和風險去推倒一切，而是體現在用外科手術般的精準、潤物細無聲的智慧，在極度複雜和約束的條件下，完成一次平穩、優雅的系統轉型。

### 大爆炸式重寫 《1812 序曲》

選擇「大爆炸式重寫」，就如同將我們的專案推向一個炮火紛飛的戰場，我們必須正面迎接以下四發致命的砲彈:

**砲彈 I：價值真空 (The Value Vacuum)**

**`時間，是現代商業戰爭中絕對的、最昂貴的、不可再生的資源。`**

想像一下，我們向 CEO 匯報：「未來兩年，我的團隊將不為公司貢獻任何新的功能或業務增長，請持續投入數百萬美元的資源。」這聽起來何其荒謬？我必須向說得出這種話的人致上最崇高的敬意，他成功做到了在地雷區中翩翩起舞的成就 - 在一頭巨龍面前企圖拿走但凡一枚金幣。

在快速變化的市場中，兩年的「價值真空期」，足以讓競爭對手將我們遠遠甩在身後，一個長達一到兩年的重寫專案，意味著，在這段漫長的時間裡，團隊無法為業務交付任何新的功能或價值。它變成了一個持續吞噬公司資源（時間、金錢、頂尖人才）卻沒有任何產出的黑洞 - 在瞬息萬變的市場競爭中，這種「價值真空期」絕對是致命的。

**Day 6 的成本分析讓我們看到真實的商業衝擊。**投資交易系統對高可用性的要求極高，因為交易中斷可能導致巨大的用戶損失、品牌信譽受損、以及法規合規風險<Day 6 | Trade-off 成本管控藝術>。如果我們花兩年時間重寫系統，這期間無法進行任何業務優化，每一個無法實現的功能需求，都可能意味著數萬美元的機會成本。

**Day 5 中家庭財務系統的使用者場景**更提醒我們價值交付的緊迫性：使用者需要預算監控、自動告警、以及即時的財務狀況掌握<Day 5 | 使用者的系統操作情境 - User Story 與 Scenario Flow>。使用者不會等待兩年才獲得這些關鍵功能，他們會直接轉向競爭對手。

**砲彈 II：無限風險 (The Unbounded Risk)**

**`這是一場只能贏不能輸的豪賭。`**

這不僅是技術風險，更是商業風險。舊系統就像一個身經百戰、滿身傷疤但仍在戰鬥的老兵；新系統則像一個未經實戰、只在模擬器上演練過的新兵。讓新兵在最關鍵的戰役中，一次性替換掉老兵，這不是勇氣，是賭博(經典案例:滑鐵盧與馬謖)。任何一個微小的、未曾預料到的場景（例如某個特定客戶的奇特數據格式），都可能導致整個新系統的崩潰。

所有資源和期望都押注在一個最終的交付日期上，沒有中途的驗證點、沒有逐步的風險釋放，也沒有下班的機會。任何一個蝴蝶煽動的翅膀，都可能導致整個專案的延期甚至失敗，而失敗的代價是災難性的，甚至沒有回頭路。

**還記得 Day 2-2 中不同系統的災難恢復需求嗎？**投資交易系統要求極短的恢復時間目標（RTO < 30 秒）和零數據丟失（RPO = 0）；健康監控系統也有嚴格的 RTO 和 RPO 要求<Day 2-2 | 需求確認 × 系統設計起點(二)：領域邊界與基礎需求確認>。大爆炸式重寫意味著，在切換的那一刻，我們必須確保新系統能完美滿足這些極端嚴苛的要求。一旦失敗，30 秒的 RTO 意味著我們沒有任何緩衝時間，損失將是即時且巨大的。

**Day 10 討論的快取雪崩風險**在大爆炸式重寫中會被無限放大：當大量快取同時失效時，所有請求會直接衝擊資料庫，造成系統崩潰；熱點數據的快取失效也會導致大量並發請求集中在同一個數據點上<Day 10 | 快取策略的哲學>。在漸進式遷移中，這些風險可以逐步暴露和修復；但在大爆炸式重寫中，所有風險會在同一時刻爆發，形成災難性的連鎖反應。

**砲彈 III：知識流失 (The Knowledge Drain)**

**`舊系統中沉澱了大量未被文件化的、隱性的商業規則與邊界條件。`**

重寫過程幾乎必然會導致這些寶貴知識的永久性流失，並在新系統中重現早已被解決過的問題。

一個運行了五年的單體系統，是公司五年商業邏輯的活化石，那些奇怪的 if-else 判斷，可能對應著某個已離職銷售冠軍簽下的大客戶的特殊需求；那個看似冗餘的數據表，可能是財務部門在季度結算時賴以生存的關鍵。重寫，就是一場組織性的記憶清除。我們以為丟掉的是技術債，但實際上，卻把寶貴的商業資產也一起扔掉了。

舊系統中沉澱了大量未被文件化的、隱性的商業規則與邊界條件。重寫過程幾乎必然會導致這些寶貴知識的永久性流失，並在新系統中重現早已被解決過的問題。

**Day 4 中 Portfolio 聚合的狀態轉換邏輯**正是這種隱性知識的典型案例：投資組合從初始狀態到活躍交易、風險管控、最終清算，每個狀態轉換背後都有複雜的業務規則和邊界條件<Day 4 | 用 DDD 建構業務邏輯：從用例到聚合設計>。這些狀態機的設計，往往是經過無數次線上問題修復後才趨於穩定的。重寫時，我們很容易遺漏某些罕見但關鍵的狀態轉換路徑。

**Day 5 中的多角色權限設計**更揭示了知識的複雜性：不同角色（交易者、風險管理員、合規官）擁有不同層次的系統訪問權限和操作範圍<Day 5 | 使用者的系統操作情境 - User Story 與 Scenario Flow>。這些權限矩陣的背後，往往對應著公司內部的政治博弈、合規要求、甚至是過去某次事故後的痛苦教訓。重寫時，這些脈絡都會消失，我們只能從零開始重新踩一遍坑。

**砲彈 IV：組織耗竭 (The Organizational Exhaustion)**

**`長此以往，無論專案最終成敗，組織的元氣與信任都已大傷。`**

重寫會創造出一個「A/B 團隊」的困境。最優秀的工程師被調往「美味可口有營養」的新專案（A 團隊），而其他人則被留在舊系統上做著吃力不討好的維護工作（B 團隊）。B 團隊會感到被遺棄、士氣低落；A 團隊則背負著未來無所知的期望，壓力巨大。最終，專案延期、內訌不斷，無論成功與否，組織都已元氣大傷。

優秀的工程師基本上等同於一位追求秩序與完美的浪漫主義理想者，沒有一個這樣子的人願意不斷的一直擔當傳球的角色而不嚮往成為全場焦點下射門的冠軍。

長週期的重寫專案會分裂團隊（維護舊系統 vs. 開發新系統），並讓所有參與者背負巨大的心理壓力，最終導致人才流失與團隊士氣的崩潰。

**Day 13 的跨團隊協作設計**揭示了大型專案中溝通成本的指數級增長：當團隊規模擴大時，我們需要明確的 API 契約規範、共享的架構文檔、以及詳細的決策記錄來確保協作順暢<Day 13 | 跨團隊協作設計>。在大爆炸式重寫中，A 團隊和 B 團隊之間的協調成本會變得極其高昂，因為他們不僅在不同的代碼庫工作，更是在不同的心理狀態下工作。

**Day 5 中家庭財務系統的多角色協作場景**，也暗示了組織分裂的風險：系統中存在著決策者、執行者、協調者等不同角色，每個角色都有各自的職責和權限邊界<Day 5 | 使用者的系統操作情境 - User Story 與 Scenario Flow>。當 A 團隊成為「決策者」、B 團隊成為「執行者」，這種不平等的權力結構會迅速瓦解團隊凝聚力，最終導致那個「跑路離職」的鬼故事成為現實。

柴可夫斯基在這首《1812 序曲》的終章動用了真實的加農砲，其音效壯烈、震撼，同時也充滿了毀滅性的力量，上述這四發砲彈，就是我們在選擇「大爆炸式重寫」時，必然會承受的炮火。

### 園丁的信條：演進式架構的核心原則 (The Gardener's Ethos: Core Principles of Evolutionary Architecture)《自新世界》

在揭示了「革命」的恐怖之後，我們正式提出「演進」的哲學。

德弗札克的《自新世界》交響曲，是在他旅居美國時，融合了對新大陸的觀察與對故鄉的思念所創作，它不是對過去的徹底割裂，而是在新的土壤上，讓舊的靈魂煥發出新的生命。這正是我們演進式架構的哲學。

優秀的架構師更像一位園丁，園丁不會剷平整個花園，而是在現有基礎上修剪、嫁接、施肥，引導花園朝著更健康、更美麗的方向生長。

**原則一：持續交付價值 (Deliver Value Continuously)**

這是演進式架構的「心跳」、是維持專案生命力的血液。

每一步演進，無論多小，都必須為用戶或業務帶來可感知的價值，我們不再追求完美的、遙遠的理想鄉，而是專注於下一個最有價值的、最小的、可交付的改進。今天優化一個 API，讓 App 快了 100 毫秒；下週將一個報表服務拆分出來，讓後台不再卡頓。每一次微小的成功，都在為整個系統注入生命力，並為團隊贏得信任與資源，形成正向的 **「飛輪效應」** 。

**Day 5 的 User Story 設計強調了價值交付的具體性。** 投資交易系統的故事要求專業交易者能在三十秒內獲得完整的持倉風險分析，以便在市場波動時快速做出加減倉決策<Day 5 | 使用者的系統操作情境 - User Story 與 Scenario Flow>。這不是空洞的技術指標，而是真實的業務價值——每一次演進都應該能讓這個「30 秒」縮短、讓決策更精準、讓風險更可控。**Day 1 的領域驅動思維**更提醒我們：技術選型必須服務於業務目的，單純因為流行趨勢而採用微服務架構是不負責任的決策<Day 1 | 系列開場與導讀：從 0 開始打造可交付的系統設計-以 AWS 為例>。

**原則二：安全至上 (Safety First)**

這是一位職業工程師的「希波克拉底誓詞 (Hippocratic Oath)」- _"Primum non nocere"（首先，不造成傷害）。_

所有的操作都必須在有安全網的情況下進行，任何的操作都不能損害現有業務的穩定性。絞殺者模式、藍綠部署、金絲雀發布... 這些技術模式的背後，都是這一條神聖的哲學原則。我們必須像拆彈專家一樣，對生產環境抱有最高的敬畏。

**Day 15 的 CI/CD 全自動化實作正是這一原則的具體實踐。**透過建立多階段的部署流程、自動化的健康檢查機制以及快速回滾能力，我們為系統演進建立了完善的安全防護網<Day 15 | CI/CD 全自動化實作>。**Day 14 的 Infrastructure as Code** 更確保了所有基礎設施變更都具備完整的版本追溯能力和回滾機制，讓團隊能夠清楚掌握每一次變更的內容與影響<Day 14 | Infrastructure as Code (Terraform)>。這些實踐讓我們能夠大膽演進，因為我們知道即使失敗，也能在幾分鐘內恢復。

**原則三：建立反饋迴路 (Build Feedback Loops)**

演進不是盲目的，我們必須讓系統「對自己說話」。

透過數據（如延遲、錯誤率）來驗證我們的改動是否真的產生了正面效益，全面的監控（Metrics）、日誌（Logging）、追蹤（Tracing）為我們的系統裝上了眼睛和耳朵。數據是我們唯一的真理來源，我們提出的每一個架構決策，都是一個「科學假說」（例如：「將用戶服務拆分出來，可以降低訂單創建的延遲」），而線上的監控數據，就是驗證這個假說的唯一標準 - **用理性與數據，驅動每一次決策**。

**Day 9 的高併發與限流設計**展示了反饋迴路的重要性：系統需要持續監控關鍵指標如請求量、響應時間和錯誤率，並根據這些數據動態調整限流策略以維持服務穩定性<Day 9 | 高併發與限流設計>。在演進過程中，這些指標會告訴我們新服務是否真的比舊系統更好。**Day 10 的快取策略分析**更強調了監控體系的重要性：快取命中率、潛在的雪崩風險、以及數據一致性延遲等指標，都是指導我們持續優化快取策略的關鍵數據<Day 10 | 快取策略的哲學>。沒有這些反饋機制，我們的演進就只是盲目的賭博。

**原則四：擁抱過渡期的不完美 (Embrace the Imperfect Transition)**

演進的過程，系統必然是「醜陋」的。新舊代碼並存，數據需要雙向同步，API Gateway 的路由規則可能很複雜。但這種「混亂」的過渡態是健康演進的標誌，而非失敗的象徵，我們必須接受並學會管理這種中間狀態的「混亂」。我們所追求的不是靜態的完美，而是富有活力的動態之美 - 這座城市永遠處於良好的建設之中，而這正是它充滿活力的證明。

**Day 12 的版本控制策略**教會我們如何在混亂中保持秩序：透過 Feature Branch 策略讓新舊代碼能夠並行開發，同時藉由嚴謹的 Pull Request 審查流程確保代碼質量不因過渡期而下降<Day 12 | 版本控制策略 × Git Flow × Lint>。在系統演進的過渡期，我們需要謹慎處理新舊系統並存時的數據同步與快取一致性問題，接受這段時間內必然產生的額外複雜性與成本。

**Day 1 的系統有機性哲學**為這個原則提供了哲學基礎：商業系統的本質是持續演化而非一次性創造，它是有機的、混亂的，為了在真實世界中生存而充滿了務實的妥協<Day 1 | 系列開場與導讀：從 0 開始打造可交付的系統設計-以 AWS 為例>。如果我們能接受系統本身就是有機演化的產物，就能更坦然地面對演進過程中的「不完美」——這不是失敗，而是生命力的證明。

## 第二樂章：宏觀戰略 - 絞殺者無花果模式

想像一下熱帶雨林中的那棵老樹（我們的單體系統），絞殺榕的種子（我們的新服務）落在它的枝幹上，向下生根，向上發芽。

起初，它很微小，依附著老樹。但隨著時間推移，它的藤蔓越來越多、越來越粗壯，最終形成一張網，徹底包裹住老樹，汲取所有陽光和養分。最後當老樹最終枯萎腐爛時，絞殺榕已經取而代代之，成為一棵獨立、茁壯的新樹。

這就是我們的宏觀核心戰略 3 要點：

1. 識別邊界 (Identify)：在單體這座老城中，找到第一個改造的街區。這個街區的邊界必須清晰，例如「用戶個人資料管理」、「產品目錄查詢」或「行動端 API 服務」。
2. 逐步替換 (Intercept & Replace)：建立新的微服務（第一根藤蔓），來處理這個街區的業務。然後，在城市的入口處設立一個「交通警察」。
3. 最終絞殺 (Strangle)：當越來越多的街區被新服務取代，藤蔓織成了一張密不透風的網，老城的核心功能幾乎都被繞過，此時就可以安全地將其「熄燈」，完成遷移。

這個過程的精妙之處在於它的漸進性與安全性的悄然無聲。在整個過程中，系統始終對外提供服務，用戶甚至感知不到內部正在發生如此劇烈的結構性變革。

### 第一步：識別邊界 (Identify the Seam)

如何找到在單體系統上「動第一刀」的地方。

選擇標準：業務邊界清晰（如用戶、產品、訂單）、改動價值高、與系統其他部分耦合度相對較低的功能。可以把它稱為尋找第一個「灘頭堡」。

種子會先長出第一根藤蔓，向下扎根。這就是我們的第一步：在龐大的單體系統中，找到一個清晰、有價值的業務邊界。這個邊界可能是一個功能模組（如：用戶認證），或是一個特定的用戶場景（如：行動裝置的 API）。

**這個識別過程，正是我們在架構選型與設計中所強調的「服務邊界識別」(Service Boundary Identification) 的實際應用。**`透過 DDD 的界限上下文 (Bounded Context) 分析，我們能夠識別出哪些業務功能具有清晰的領域邊界、獨立的業務邏輯，以及最小的外部依賴`<Day 7 | 架構選型與設計>。同時，**Day 13 中討論的 OpenAPI 規範與契約先行設計**，為我們提供了定義這些邊界的具體工具：`在開始拆分之前，我們需要先用 OpenAPI 定義清楚新舊系統之間的 API 契約，確保邊界的清晰與可測試性`<Day 13 | 跨團隊協作設計>。

此外，**資料庫層面的邊界識別同樣關鍵**。如 Day 11 所探討的，`數據層往往是單體系統中最難切分的部分，我們需要分析聚合根 (Aggregate Root) 的資料依賴關係，識別出可以獨立管理其資料生命週期的業務實體`<Day 11 | 資料庫設計哲學>。

### 第二步：逐步替換 (Gradually Replace)

建立新的微服務來實現被識別出的功能。

蔓會越長越多（我們開發了更多的新服務），它們會纏繞著老樹的樹幹，吸收陽光和養分。在我們的世界裡，這意味著我們會放置一個流量控制中心設置一個代理或閘道，將指向該功能的特定請求「攔截」，並將其「改道」。它就像一個聰明的路由器，將指向新功能的請求（例如 /api/v2/...）導向新生的服務，而其餘的請求，則繼續由老樹（單體系統）處理。

此時，新舊系統處於「共存」狀態，安靜地共同對外提供服務。

**這個逐步替換的過程，需要我們整合多個先前聊過的的技術能力。** 首先，**Day 6 的成本管控藝術為我們提供了服務選型的決策框架**。在當時的案例場景中，我們會面臨投資交易系統需要小於 100 毫秒的響應時間但 Lambda 冷啟動可能超過 100 毫秒的困境，家庭財務系統對成本極度敏感但 ECS 最低配置月費 58 美元仍超預算的窘境，以及健康監控系統的物聯網數據流需要長時間運行但 Lambda 有 15 分鐘執行限制的技術衝突<Day 6 | Trade-off 成本管控藝術>。

這些看似無解的矛盾，實際上揭示了服務選型的本質:不同系統有著截然不同的成本模型與優化目標。投資交易系統採用性能優先模型，成本敏感度低，延遲最小化優先於可用性最大化優先於成本控制，寧可過度配置也不能性能不足;家庭財務系統則採用成本敏感模型，成本敏感度高，成本控制優先於基本功能滿足優先於性能提升;健康監控系統使用平衡優化模型，成本敏感度中等，穩定性優先於成本控制優先於高級功能<Day 6 | Trade-off 成本管控藝術>。

對於 BFF 這種輕量級的聚合層，Lambda 通常是理想選擇；而對於需要長時間運行或有複雜狀態管理的服務，ECS 可能更合適。更進一步，當我們考慮多區域部署時，決策複雜度會呈指數級增長:投資交易系統採用美國東部、歐洲西部、亞洲東北部的多區域部署，雖然基礎設施成本增加 200%且跨區域數據傳輸每 GB 收費 0.02 美元，但延遲從美歐 150 毫秒降至 20 毫秒、美亞 200 毫秒降至 30 毫秒，年投資回報率達到 15 比 1;家庭財務系統則選擇單區域加 CDN 方案，區域成本每月 100 美元對比多區域每月 400 美元，加上 CDN 每月 20 美元，總體節省 70%成本;健康監控系統採用分層策略，核心單區域每月 500 美元加上每個區域處理每月 200 美元總計 1100 美元，對比完全多區域每月 1500 美元更具性價比<Day 6 | Trade-off 成本管控藝術>。

**Day 14 的 Infrastructure as Code 實踐至關重要**。在沒有基礎設施代碼化的時代，我們會面臨三大致命困境:配置漂移導致手動調整無法追蹤，測試與生產環境行為不一致;災難恢復的不確定性，凌晨三點當機時需要六小時重建，完全依賴個人記憶回想所有手動配置步驟;擴展瓶頸，申請資源三天配置環境五天，無法快速響應市場需求<Day 14 | Infrastructure as Code (Terraform)>。

更可怕的是知識集中風險:新人問如何部署程式碼，資深工程師需要回想首先 SSH 到伺服器然後 git pull 接著重新編譯記住要重啟 nginx 還有清除快取對了別忘了備份資料庫...當關鍵人員離職後無人知道完整部署流程，生產環境配置只存在於某個人的腦海裡<Day 14 | Infrastructure as Code (Terraform)>。

因此我們需要用 Terraform 來管理新服務的基礎設施，包括 API Gateway 的路由規則、Lambda 函數的配置、ECS 服務的定義等，確保基礎設施的版本化與可回滾性。具體而言，生產環境需要配置 instance_type 為 t3.medium、最小規模 2 最大規模 10 期望容量 3、資料庫實例類別 db.t3.medium 分配儲存空間 100GB;開發環境則配置 instance_type 為 t3.micro、最小規模 1 最大規模 3 期望容量 1、資料庫實例類別 db.t3.micro 分配儲存空間 20GB<Day 14 | Infrastructure as Code (Terraform)>。

更關鍵的是，**Day 15 的 CI/CD 全自動化實作為我們提供了安全的部署機制**。還記得那些手動部署的恐怖回憶嗎?週五下午五點部署新功能，同事集體阻止說週五不要部署如果出問題要加班到週末;環境不一致災難，在我的電腦上明明可以運行但測試環境就是有 bug 生產環境又跟測試環境不一樣;部署流程黑盒子，新人問如何部署，資深工程師需要回想 SSH、git pull、重新編譯、重啟 nginx、清除快取、備份資料庫等 N 個步驟<Day 15 | CI/CD 全自動化實作>。為了避免這些鬼故事重演，我們需要建立完整的 GitHub Actions 碎片化管理流程:第一層基礎檢查執行 code-quality 並設定 10 分鐘超時實現快速失敗;第二層測試執行並行跑 unit-tests、integration-tests、e2e-tests 設定 15 到 30 分鐘超時並採用 matrix 策略多版本測試;第三層安全品質檢查執行 security-scan 設定 15 分鐘超時包含 SAST 和依賴掃描;第四層建置部署準備執行 build 設定 10 分鐘超時產生 artifacts;第五層環境部署執行 deploy-staging 和 deploy-production 設定 10 分鐘超時基於環境條件觸發<Day 15 | CI/CD 全自動化實作>。透過多階段的審批流程和自動化的流量切換，我們可以實現從 10% → 50% → 100% 的漸進式流量遷移，並在任何階段發現問題時快速回滾。

在這個過渡期，**Day 10 的快取策略變得特別重要**。由於新舊系統可能需要暫時維持雙寫，我們必須面對快取一致性的核心困境:投資交易系統需要強一致性但會犧牲 50%性能;家庭財務系統接受最終一致性但協作衝突難以解決;健康監控系統需要因果一致性但實現複雜度極高需要向量時鐘等技術<Day 10 | 快取策略的哲學>。

但我們必須警惕快取雪崩與擊穿災難:大量快取在同一時刻集體失效例如服務重啟或相同 TTL 設定，請求洪水瞬間淹沒資料庫;熱點數據快取剛好失效，無數請求繞過快取直接打在資料庫同一個數據點，像用放大鏡聚焦陽光輕易燒穿一點<Day 10 | 快取策略的哲學>。我們必須謹慎處理快取失效策略，確保兩個系統之間的資料最終一致性。

最後，**Day 12 的版本控制策略幫助我們管理這種複雜的並行開發**。Feature Branch 並行開發會遇到合併地獄:多個 feature 分支同時開發，合併到 develop 時出現大量衝突;subfeature 必須先合併到 feature，feature 必須先合併到 develop，develop 測試後才能開 release 分支，release 穩定後才能合併到 main，任何環節失敗都會阻塞整條 pipeline<Day 12 | 版本控制策略 × Git Flow × Lint>。

為了確保代碼品質，我們需要建立審核流程的三方門檻:同儕審核門檻確認架構與風格避免 service 與 repository 混淆;業務審核門檻確認單一環境下最完美的業務執行率;品質審核門檻驗證多環境下最大覆蓋率的業務執行成功率<Day 12 | 版本控制策略 × Git Flow × Lint>。我們需要在同一個代碼庫中維護單體系統的修復和新微服務的開發，Feature Branch 策略和嚴格的 PR 審查流程變得至關重要。

### 第三步：持續絞殺 (Continue the Strangulation)

重複前兩個步驟，逐步將更多功能遷移到新的微服務中，讓新的「藤蔓」越長越多。

數年後，無花果藤蔓已經變得如此粗壯，形成了一個新的、獨立的樹幹結構，而內部那棵老樹，因為再也接收不到陽光，最終枯萎、腐爛、消失。在我們的系統中，當所有流量都已經被導向新服務後，舊單體系統的核心職責逐漸被掏空，老系統就可以被安全地下線，完成歷史使命（老樹自然枯萎）。

**這個持續演進的過程，需要我們具備全面的系統思維和長期的技術視野。Day 9 討論的高併發與限流設計在這裡發揮關鍵作用**。如果我們沒有妥善處理併發瓶頸，將會面臨應用層瓶頸識別失敗的災難:連接池資源耗盡導致新請求全部阻塞;任務排隊積壓從 1 分鐘暴增至 10 分鐘;記憶體 GC 停頓導致 P99 延遲從 50 毫秒惡化至 5000 毫秒<Day 9 | 高併發與限流設計>。

更可怕的是資料庫層瓶頸災難:慢查詢比率突然飆升單次 SQL 查詢耗時從 10 毫秒惡化至 10000 毫秒;索引命中率下降導致全表掃描 QPS 從 5000 跌至 50;鎖等待死鎖連鎖反應交易全部阻塞系統完全癱瘓;連線池使用率 100%新連線全部 timeout<Day 9 | 高併發與限流設計>。

因此，隨著越來越多的流量被導向新服務，我們需要為每個新服務設計適當的限流策略，使用 Token Bucket 或 Sliding Window 算法來保護服務免受突發流量的衝擊，特別是在流量切換的關鍵時刻。在 AWS 架構選擇上，計算層可採用 ECS Fargate 提供無服務器容器自動擴縮的成本效益，或 Lambda 提供事件驅動極致彈性的按使用付費，或 ECS EC2 提供完全控制成本優化的穩定負載;存儲層可採用 RDS 或 Aurora 提供關係型 ACID 複雜查詢，或 DynamoDB 提供 NoSQL 無限擴展微秒延遲，或 S3 加 Athena 提供數據湖分析查詢成本最優;緩存層可採用 ElastiCache 提供分散式 Redis 或 Memcached 高可用，或 DAX 提供 DynamoDB 加速透明緩存微秒延遲，或 CloudFront 提供全球 CDN 邊緣緩存靜態內容<Day 9 | 高併發與限流設計>。

**Day 8 的原子化架構思維幫助我們理解前後端的協同演進**。但在實踐中我們會遇到前後端協同的邊界模糊困境:service 商業邏輯應用段與 repository 與外部系統介接段混淆誤用，雖然功能正常但隨著程式碼增長邏輯抽換不乾淨成為屎山<Day 8 | 設計系統與原子化架構>。

為了解決這些困境，我們需要採用 Atomic Design 層次化實現:原子層 Atoms 對應 StatusBadge、QRCode、PriceDisplay 等領域值對象 UI 表達;分子層 Molecules 對應 TicketInfo 將相關值對象組合成有意義 UI 片段;有機體層 Organisms 對應 TicketCard 完整業務功能實現對應聚合核心能力;模板層 Templates 對應 TicketRedemptionWorkflow 跨聚合業務流程;頁面層 Pages 對應 CoffeeRedemptionPage 特定角色情境完整操作<Day 8 | 設計系統與原子化架構>。當我們將後端服務拆分為微服務時，前端的組件架構也需要相應調整。BFF 模式正是這種前後端邊界重新定義的產物，它將後端的聚合根 (Aggregate) 映射為前端友好的 API，實現了領域模型到 UI 組件的優雅橋接。

**Day 3 和 Day 4 中深入探討的抽象建模和 DDD 聚合設計**，為我們提供了持續演進的理論基礎。但領域邊界識別存在核心困境:過度細分導致聚合過小產生分散式事務地獄;過度合併導致聚合過大違反單一職責原則;上下文映射混亂導致團隊對同一概念有不同理解<Day 3 | 需求萃取方法論-抽象建模(Abstract Modeling)>。每一次新的服務拆分，都需要重新審視領域邊界，確保我們提取的不僅是技術上的模組，更是業務上有意義的聚合根。從概念建模到行為建模，從資料建模到架構建模，四重建模框架確保了每次演進都是深思熟慮的結果<Day 3 | 需求萃取方法論-抽象建模(Abstract Modeling)>、<Day 4 | 用 DDD 建構業務邏輯：從用例到聚合設計>。

**Day 5 的使用者操作情境分析提醒我們**，系統演進的最終目的是為使用者創造價值。User Story 必須包含明確的技術約束需求:投資交易系統需要響應時間小於 100 毫秒、併發 2000+TPS、強一致性、交易狀態複雜;家庭財務系統需要成本敏感、協作衝突處理、最終一致性、間歇性使用;健康監控系統需要 IoT 數據流處理、設備數量增長、時序一致性、背景分析任務<Day 5 | 使用者的系統操作情境 - User Story 與 Scenario Flow>。每一個被拆分出來的微服務，都應該對應到明確的 User Story 和操作情境，確保技術架構的改變能夠轉化為用戶體驗的提升或業務能力的增強。

最終，**這個三步走的演進框架，是我們從 Day 1 到 Day 15 所有學習內容的集大成應用。** 它證明了系統架構的優雅演進，不是依靠某一個單一的技術方案，而是需要整合領域建模、使用者體驗設計、成本權衡、架構模式、性能優化、資料管理、工程實踐、以及自動化基礎設施等多個維度的知識，才能實現真正的、可持續的系統轉型<Day 1 | 系列開場與導讀:從 0 開始打造可交付的系統設計-以 AWS 為例>。

**而 Day 2 中探討的商業邏輯轉化方法論**，更提醒我們每一次架構演進的背後，都應該有清晰的商業價值支撐。我們不是為了微服務而微服務，而是為了更好地服務於業務需求、降低變更成本、提升團隊效率。從需求的現象層、本質層到存在層的三層分析，幫助我們理解每一次演進決策背後的真正動機<Day 2-1 | 需求確認 × 系統設計起點(一):商業邏輯的轉化發>。

## 第三樂章：精準的第一擊 - BFF 作為絞殺策略的灘頭堡

### 前端模式的後端 BFF (Backend for Frontend) 核心理念

我們必須先回到原點，徹底理解 BFF 的「初心」是什麼。

忘掉它是一個後端技術，從哲學上講， **BFF 本質上是一個前端概念** 。它的誕生，是為了解決一個日益尖銳的矛盾： `通用後端 API (One-Size-Fits-All API) 與日益多樣化的前端體驗之間的矛盾`。

想像一下我們的單體系統，它提供了一套通用的 RESTful API。這套 API 就像一件均碼的 T-shirt，試圖讓所有人都穿上。

- 手機 App (Mobile Client) 走過來，它抱怨：「這件 T-shirt 太大了！我只需要 username 和 avatar 兩個欄位，我們卻給了我 50 個欄位的完整 User Profile，浪費我的流量和電力。而且，我為了顯示首頁，要分別呼叫 /user, /notifications, /timeline 三個 API，在 3G 網路下簡直是災難。」
- 網頁端 (Web Client) 接著說：「對我來說，這件 T-shirt 又有點小。我需要更豐富、更複雜的數據結構來渲染我的儀表板，我們這個 API 太過簡化，我得在前端自己組合加工數據，搞得前端邏輯很臃腫。」
- 第三方開發者 (3rd-party Dev) 最後補充：「這個 API 天天都在改，能不能給我一個穩定、有版本控制的介面？我只是想拿個商品列表而已。」

看到了嗎？「一體適用」的後端，最終結果是 **「無人適用」** 。每個前端都在妥協，都在做著本不該它做的工作。

> **`BFF 的核心理念，就是「權責反轉」。`**

它宣告： **「與其讓後端定義一套自認為通用的標準，不如讓每個前端體驗的『代言人』，為自己量身打造一個專屬的後端。」**

這個「代言人」，就是 BFF，所以，我們會看到：

- `iOS-BFF`
- `Android-BFF`
- `WebApp-BFF`

每個 BFF 的唯一使命，就是以最高效率、最少請求、最理想的數據格式服務於它對應的那個前端，它是一個翻譯官、聚合器、裁縫師。這個理念上的轉變，是理解後續戰略的基礎。

### BFF 如何應用 - 灘頭堡戰略

現在，我們將這個理念，應用到「絞殺單體」這個宏大的戰役中 - 那為何 BFF 是完美的「灘頭堡」？

在軍事上，選擇灘頭堡有幾個關鍵原則：易於攻佔、便於防守、且具有戰略價值，能為後續主力部隊的登陸創造條件，BFF 都完美符合這所有條件。

- 易於攻佔 (最小政治阻力與技術複雜度):

  - 政治上： 我們在公司內部推動這個專案時，可以不叫「單體系統重構計畫」，而叫「行動端用戶體驗優化專案」。後者的說法，更容易獲得產品經理和業務方的支持。我們不是在挑戰維護單體系統的「老衛兵」，我們是在賦能前端團隊，阻力最小。
  - 技術上： 它的邊界極其清晰——就是那個 App。我們不需要深入單體系統最複雜的業務核心去動手術，我們只需要搞清楚：「為了渲染 App 的首頁，我需要調用舊系統的哪幾個 API？」這是一個相對簡單的外部觀察，而非內部改造。

- 便於防守 (清晰的作戰邊界):

  - BFF 的職責是固定的，它的服務對象是唯一的。這意味著它的需求來源單一，不會有來自四面八方的需求變更。這使得這個新建立的服務非常穩定，易於維護和測試，確保了我們第一個陣地的穩固。

- 巨大的戰略價值 (立即的戰術勝利):

  - 價值可見： 如前所述，BFF 能立即帶來可衡量的性能提升。App 載入更快、更省電，這份「戰報」會非常亮眼，能迅速建立起團隊和領導層對新架構的信心。
  - 建立橋頭堡： BFF 的成功，不僅僅是它自身的成功，它為我們後續的絞殺行動，建立了一個關鍵的基礎設施和知識庫。團隊透過 BFF 的開發，學會了如何部署 Lambda、如何配置 API Gateway、如何設定監控。我們已經悄悄地把未來的「主力部隊」送上了岸。

選擇 BFF，就是選擇了整場戰役中，最容易啃下來、功勞又最顯著的一塊硬骨頭。

### 纏繞第一根藤蔓：BFF 如何啟動絞殺進程

好了，灘頭堡已經選定，我們如何讓第一根藤蔓開始纏繞？

**階段一：被動代理與數據聚合 (Passive Proxy & Aggregation)**

最開始，BFF 甚至不需要自己寫任何業務邏輯，它的工作模式非常「被動」。

1. 流量攔截： 透過 API Gateway，我們將 App 的第一個 API 請求，例如 GET /api/mobile/homepage，從指向單體系統，改為指向我們的 Mobile-BFF。注意，僅此一個 API，其餘所有 App 的 API 請求，仍然穿透 API Gateway，繼續打到舊的單體系統。風險被控制在最小。
2. API 聚合： 現在，Mobile-BFF 收到了這個請求。它內部所做的事情，可能就是並發地調用舊單體系統的三個 API：GET /api/v1/user/123, GET /api/v1/timeline/123, GET /api/v1/ads/for-user/123。
3. 數據裁縫： BFF 拿到這三個 API 返回的、臃腫的 JSON 數據後，從中挑選出 App 真正需要的欄位，組合成一個乾淨、輕量的新 JSON 結構，然後返回給 App。

在這個階段，絞殺已經悄然開始，雖然業務邏輯仍在單體中，但單體系統已經失去了對「行動端 API 契約」的定義權。API 的最終形態，現在由 BFF 決定，老樹的一小塊樹皮，已經被藤蔓覆蓋。

**階段二：功能蠶食與邏輯遷移 (Active Logic Migration)**

灘頭堡穩固後，藤蔓開始變得更具侵略性，我們不再滿足於只做數據聚合。

1. 新功能開發： 假設產品需要在 App 上增加一個「點讚」功能。這個 POST /api/mobile/posts/{id}/like 的請求，我們直接在 BFF 中實現其業務邏輯。BFF 收到請求後，可能會直接操作資料庫（在嚴格的權限控制下），或者調用一個新建的、極小的「點讚微服務」。這個新功能的程式碼，從未在單體系統中存在過。
2. 舊功能遷移： 我們發現單體系統中的「更新用戶個人資料」功能非常緩慢且 Bug 很多。現在，我們可以將這個功能的邏輯，完整地從單體系統中「複製」或「重寫」到 BFF (或者一個新的 User 微服務) 中。然後，透過 API Gateway 將 PUT /api/mobile/profile 的流量，從指向單體，切換到指向 BFF。

**階段三：最終絞殺**

重複階段二的過程。每完成一個功能的遷移，藤蔓就纏得更緊一分，單體系統中，那些曾經服務於行動端的程式碼，慢慢變成了「殭屍程式碼 (Zombie Code)」——它們依然存在，但再也沒有任何流量會觸及它們。

當所有來自 Mobile App 的流量，都不再指向單體系統，而是由 Mobile-BFF 全權處理時，針對「行動端」這個業務維度的絞殺就完成了。老樹上，面向南方的所有樹枝都已枯萎，因為陽光（流量）完全被新的藤蔓所遮蔽。

這時，我們就可以安全地走進單體系統的程式碼庫，將那些殭屍程式碼徹底刪除。每一次刪除，都是一次勝利的宣告。

總結一下，BFF 啟動絞殺的進程是：

1. 奪取控制權： 從代理流量開始，奪取 API 的定義權。
2. 建立新秩序： 在自己的地盤上（BFF），實現新功能，建立新的、更優雅的邏輯。
3. 蠶食舊世界： 逐步將舊的邏輯遷移過來，讓單體系統中的對應部分失效。
4. 宣告勝利： 當一個完整的業務邊界（例如「行動端體驗」）被完全覆蓋後，清除單體中的廢棄程式碼。

## 第四樂章：AWS 實戰藍圖 - 平滑的流量遷移指揮

第四樂章是整部交響曲的華彩片段，是理論與現實交匯的地方。一個再完美的戰略，如果沒有精良的工具和清晰的施工藍圖，也只會是紙上談兵，我們不只要畫出圖，更要理解圖上每一個元件的職責、邊界與互動。

### 重溫藍圖：從「混沌」到「有序」

首先，再次將兩個狀態的對比清晰地刻在腦中。

**演進前 (The Monolithic State):**

這是一個單一入口、責任模糊的狀態。所有請求，不論來自何方、目的為何，都湧向同一個目的地。

```
Client (Mobile/Web) → ALB/ELB → Monolith (EC2/ECS Cluster)
```

**演進中 (The Evolutionary State):**

這是一個權責分明、流量被精準指揮的狀態。我們的指揮家——API Gateway——站到了舞台中央。

```
Mobile Client  ┐
Web Client     ├→ API Gateway → AWS Lambda (BFF) → Monolith's Internal API/DB
               └→ API Gateway → ALB/ELB → Monolith
```

現在，我們來逐一解構這個新狀態下的核心元件，理解它們各自的角色以及如何協同作戰。

### A. 總指揮中心：Amazon API Gateway

如果說整個遷移是一場精密的軍事行動，API Gateway 就是我們的作戰指揮中心。它不是一個簡單的請求轉發器，而是一個集路由、安全、監控、治理於一身的智慧大門。

**核心職責：平滑的流量調度**

這是它最核心、最神奇的功能——基於路徑的路由 (Path-based Routing)。在 API Gateway 中，我們會定義如下的規則集：

| 優先級 | HTTP 方法 | 資源路徑 (Resource Path)  | 集成目標 (Integration Target)      | 說明                                                                                                 |
| ------ | --------- | ------------------------- | ---------------------------------- | ---------------------------------------------------------------------------------------------------- |
| 1      | ANY       | `/api/v2/mobile/{proxy+}` | Lambda Function: Mobile-BFF-Lambda | [絞殺規則] 所有 V2 mobile 的請求，都交給新的 BFF 處理。`{proxy+}` 是貪婪變數，匹配其下的所有子路徑。 |
| 2      | ANY       | `/{proxy+}`               | HTTP Proxy: ALB of the Monolith    | [預設規則] 其他所有不匹配上述規則的請求，繼續發往舊的單體系統。                                      |

這套規則的威力在於：

**無感知遷移：** 對於客戶端（Mobile App）來說，它訪問的域名從未改變。它不知道自己的請求在雲端已經被悄悄地送往了不同的目的地。

**低風險變更：** 需要將一個新的 API (`/api/v2/mobile/profile`) 從單體遷移到 BFF 時，我們不需要重新部署任何一行程式碼。我們只需要在 API Gateway 的控制台中，新增或修改一條路由規則。這是一個可以在幾分鐘內完成且能快速還原的操作。

**金絲雀發布 (Canary Deployments)：** API Gateway 還支持更高級的流量分配。我們可以設定將 `/api/v2/mobile/search` 的 10% 流量發送到新 BFF，90% 流量發送到舊單體。這讓我們可以在真實的生產環境中，用一小部分流量來驗證新服務的穩定性，這是實現「平滑」遷移的終極武器。

**附加職責：卸載通用能力**

除了路由，API Gateway 還像一個能幹的副官，幫我們處理了大量通用事務：

- **認證與授權 (Authentication/Authorization):** 它可以直接校驗傳入的 JWT (JSON Web Token) 或 API Key，只有合法的請求才能進入後端，極大地簡化了 BFF 和單體系統的安全邏輯。
- **請求校驗與轉換 (Request Validation/Transformation):** 確保請求格式的正確性。
- **速率限制與節流 (Rate Limiting/Throttling):** 保護後端服務不被惡意流量沖垮。

### B. 精銳作戰單元：AWS Lambda (或 Fargate)

Lambda 是我們執行「灘頭堡」戰術的輕騎兵或特種部隊。它是運行 BFF 服務的理想平台。

**為何選擇 Lambda？**

**專注業務 (Focus on Business Logic):** 我們只需要上傳我們的 BFF 程式碼（例如一個 Node.js/Python/Go 應用）。我們無需關心底層伺服器的作業系統、補丁、擴容。AWS 會處理一切。

**事件驅動與彈性伸縮 (Event-driven & Scalable):** Lambda 根據請求的數量自動擴展。沒有請求時，它不運行，成本為零。當流量洪峰（例如 App 推播活動）到來時，它可以瞬間擴展出成百上千個並發執行環境來應對。這種彈性是傳統 EC2 難以比擬的。

**低運維成本 (Low Operational Overhead):** 尤其在遷移初期，BFF 的功能和流量都有限，為它維護一個 7x24 小時運行的 EC2 實例是種浪費。Lambda 的按需付費模式完美契合此場景。

**BFF Lambda 內部的運作：**

它從 API Gateway 接收到請求後，執行我們在第三樂章學到的核心邏輯：

1. 解析請求，獲取用戶身份等資訊。
2. 並發地向單體系統的內部 API (或直接查詢其資料庫) 發起 1 到 N 個請求。
3. 等待所有請求返回，將數據聚合、裁剪、轉換成行動端最需要的格式。
4. 返回一個單一、乾淨的回應給 API Gateway，再由後者傳回手機。

### C. 安全信使：IAM Roles

IAM (Identity and Access Management) 是整個 AWS 宇宙的安全基石。在這裡，它扮演著精確授權的角色，確保我們的 BFF Lambda 不會「越權」。

這是一個**最小權限原則 (Principle of Least Privilege)** 的經典應用。我們會為 Mobile-BFF-Lambda 創建一個專屬的執行角色 (Execution Role)，這個角色身上會掛著幾份權限聲明 (Policy)：

**基本執行權限：** 允許 Lambda 將日誌寫入 Amazon CloudWatch Logs。

**網路訪問權限：** 如果單體系統部署在 VPC 內，需要授權 Lambda 函數可以掛載到該 VPC 的指定子網和安全組，從而讓它在網路上能夠「看到」單體系統的伺服器。

**資源訪問權限 (過渡階段的權衡):**

- **上策 (API Call):** 如果單體有內部 API，則此處無需特殊權限，只要網路可達即可。
- **中策 (DB Access via Secrets Manager):** 授權 Lambda 可以從 AWS Secrets Manager 中讀取單體資料庫的唯讀帳號密碼，然後進行查詢。這是最常見的過渡方案。
- **下策 (Direct DB Credential):** 將資料庫密碼寫在環境變數中，風險較高。

IAM 確保了即使 BFF 的程式碼出現漏洞，其能造成的破壞也被限制在一個極小的範圍內。它就像是給了 BFF 一張目的地的通行證，但這張通行證上精確地寫明了它只能訪問哪些房間、操作哪些設備。

### D. 戰情儀表板：Amazon CloudWatch & AWS X-Ray

如果說 API Gateway 是指揮中心，那麼 CloudWatch 和 X-Ray 就是我們的情報與偵察系統。沒有數據的演進是盲目的賭博。

**如何利用它們來指揮遷移？**

**建立對比儀表板 (Comparison Dashboard):** 在 CloudWatch Dashboard 中，我們創建並排的兩個視圖：

**左側：新路徑性能**

- API Gateway `/v2/mobile` 路徑的請求計數、P90/P99 延遲、4xx/5xx 錯誤率。
- Mobile-BFF-Lambda 的調用次數、執行時間、錯誤率、節流次數。

**右側：舊路徑性能**

- ALB 的請求計數、目標響應時間。
- Monolith EC2/ECS 叢集的 CPU/Memory 使用率。

這個儀表板能讓我們用數據客觀地回答：「我們的遷移是否帶來了正向收益？」

**設定關鍵警報 (Critical Alarms):**

- 如果 Mobile-BFF-Lambda 的錯誤率在 5 分鐘內超過 1%，立即透過 SNS 發送警報到團隊的 Slack/Email。
- 如果 API Gateway 的 P99 延遲超過 500ms，立即告警。

這些警報是我們的哨兵，確保我們在問題擴大前就能介入。

**深度診斷 (Deep Diagnostics with X-Ray):**

當儀表板顯示新路徑變慢時，我們如何定位問題？是 API Gateway 的錯？還是 Lambda 慢了？還是 Lambda 調用單體時變慢了？

只要啟用 X-Ray，它會為我們繪製出一張完整的**服務地圖 (Service Map)** 和**追蹤詳情 (Trace Details)**。我們會清晰地看到一個請求的完整生命週期：

```
Client -> API Gateway (5ms) -> Lambda (150ms) -> [Call Monolith /getUser (120ms)] -> Lambda -> Client
```

透過這張圖，我們可以立刻識別出性能瓶頸在於對單體 `getUser` 服務的調用上。X-Ray 是從「發現問題」到「定位問題」的關鍵橋樑。

## 終章：持續演進的飛輪

一個沉重的飛輪，在第一次推動時需要巨大的力氣。這就是我們建立第一個 BFF、配置第一條路由規則的過程——充滿了學習、試錯與政治溝通。但是，一旦它開始轉動，慣性會讓後續的每一次推動都變得更加輕鬆。

每一次成功的遷移，都在為這個飛輪注入新的能量，最終它會自己轉動起來，帶動整個組織的技術文化向前演進。這股能量，由三個相互增強的部分組成：

### 技術飛輪：能力的沉澱與複用

第一次的成功，為我們留下了一筆寶貴的技術資產。

**可複用的基礎設施即代碼 (IaC)：** 我們為 Lambda 和 API Gateway 編寫的 Terraform 模組 (Day 14)，在下一次遷移 Web-BFF 時，可以直接複用，將部署時間從數天縮短到數小時。

**成熟的 CI/CD 流程：** 我們建立的自動化測試、審批與金絲雀發布流程 (Day 15)，已經成為團隊的標準作業程序 (SOP)。新服務的交付不再是充滿不確定性的冒險，而是一個可預測、安全的標準流程。

**標準化的可觀測性：** 我們建立的 CloudWatch 儀表板和 X-Ray 追蹤實踐，成為了所有新服務的「出廠標配」。團隊擁有了統一的語言來討論性能與問題。

這意味著，每一次演進的邊際成本都在顯著降低。我們不再需要從零開始，而是在一個堅實的平台上，不斷地進行「複製-修改-部署」的循環。

### 組織飛輪：信任的複利與知識的擴散

技術的成功，最終會轉化為組織的變革。

**信任的複利：** 第一次 BFF 的成功，用數據證明了演進式架構的價值（「行動端 P99 延遲降低 80%」）。這份戰報為你贏得了管理層的信任與政治資本。當你提出下一個遷移計畫時，遇到的阻力會大大減小，獲得的資源會更加充足。

**知識的擴散：** 第一個成功的團隊，會成為組織內的「黃埔軍校」。他們的經驗、教訓、甚至是失敗的嘗試，都會成為其他團隊寶貴的學習資料。他們建立的最佳實踐，會逐漸擴散，成為整個技術部門的共同財富。

**敏捷的賦能：** 隨著越來越多的功能被拆分出來，團隊的自主權也越來越高。前端團隊可以與他們的 BFF 團隊快速迭代，而無需再等待單體系統那漫長的發布排程。這打破了組織的瓶頸，真正釋放了團隊的敏捷性與創造力。

這個飛輪的轉動，正在悄悄地改變組織的 DNA，從一個中央集權、反應遲緩的結構，演變為一個分佈式、快速響應的網絡。

### 價值飛輪：從技術指標到商業影響

最終，所有的努力都必須回歸商業價值。

**更快的產品上市時間 (Time to Market)：** 組織的敏捷性，直接轉化為新功能可以更快地交付到用戶手中，讓我們在市場競爭中佔得先機。

**更優的用戶體驗：** 系統性能的提升、錯誤率的降低，直接提升了用戶滿意度和留存率。

**更強的人才吸引力：** 沒有優秀的工程師願意將自己的職業生涯浪費在維護一個陳舊的、無人能懂的單體系統上。一個持續演進、擁抱現代技術的環境，是吸引和留住頂尖人才的關鍵。

這個飛輪確保了技術的投入，能夠持續地轉化為可見的商業回報，從而形成一個 **「投入 → 產出 → 再投入」** 的良性循環。

### 總結

我們將今天所有關於「架構演進的協奏曲」，從背後的哲學思想到 AWS 的實戰藍圖，濃縮為以下三大核心層次的思維轉變：

1. **哲學層**：從「英雄式革命」到「園丁式演進」：我們的討論始於一個根本性的心態轉變：拒絕「大爆炸式重寫」那充滿英雄主義誘惑、卻隱含巨大風險的革命道路。我們選擇成為一位務實的園丁或指揮家，承認現存系統的有機性與歷史價值，透過持續修剪、嫁接與引導，確保業務的航船在演進過程中永不中斷航行。

2. **戰略層**：從「全面開戰」到「灘頭堡登陸」：我們將宏大的遷移目標，分解為一套精準、可執行的軍事戰略。我們採用「絞殺者無花果模式」作為總體指導方針，並選擇「BFF (Backend for Frontend)」作為價值最高、邊界最清晰、風險最低的「灘-頭堡」，發動第一場必勝的登陸戰，以此建立技術信心與組織信任。

3. **戰術層**：從「手動施工」到「雲端指揮作戰」：我們不再依賴人工操作，而是利用 AWS 這套現代化的作戰指揮系統。透過 API Gateway 進行流量的精準調度、Lambda 作為執行突擊任務的輕騎兵、IAM 確保行動的安全授權，並由 CloudWatch/X-Ray 提供全方位的戰場情報，將一場混亂的遷移，轉變為一場可觀測、可控制、可回滾的優雅演習。

> **關鍵要點**：
>
> - **演進，而非重建 (Evolve, Don't Rewrite)**：這是我們的最高指導原則。大爆炸式重寫是充滿誘惑的陷阱，它會帶來價值真空、無限風險、知識流失與組織耗竭。真正的優越，是在約束中完成優雅的轉身。
> - **BFF 是完美的「第一擊」 (BFF as the Perfect First Strike)**：選擇 BFF 作為絞殺策略的起點，是因為它能以最小的技術與政治阻力，換取最快、最顯著的用戶體驗提升，是啟動整個演進飛輪的最佳槓桿點。
> - **價值驅動的飛輪 (The Value-Driven Flywheel)**：演進不是一個專案，而是一個持續的過程。每一次成功的、微小的價值交付（例如優化一個 API），都在為技術、組織與商業價值三個飛輪注入能量，最終形成一個自我驅動、持續進步的良性循環。
> - **入口即是控制點 (The Entry Point is the Control Point)**：絞殺者模式的精髓，在於透過 API Gateway 這樣的代理層，在不改動舊系統的情況下，和平地奪取流量的控制權。誰掌握了入口，誰就掌握了演進的節奏與方向。
>
> ### **最終的成就，不是交付一個靜態的「完美系統」，而是成功孕育出一個具備「持續演進能力」的組織與文化。我們建造的不只是一座新的城市，更是這座城市自我更新、生生不息的生命力。**
