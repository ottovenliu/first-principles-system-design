# D√≠a 15 | Implementaci√≥n de Automatizaci√≥n CI/CD Completa - GitHub Actions √ó CodePipeline √ó CodeBuild: Pipeline de Integraci√≥n y Despliegue Continuo y Gesti√≥n de Segmentaci√≥n de Tareas

En el desarrollo de software moderno, no solo debemos enfocarnos en la calidad del c√≥digo, sino tambi√©n asegurar la fiabilidad de todo el proceso de entrega. ¬øRecuerdas lo que mencionamos en <Estrategia de Control de Versiones (Estrategia de Revisi√≥n de PR)>: `Imagina que cada PR es como una "propuesta de producto" que debe pasar por un riguroso "proceso de revisi√≥n" antes de poder ser incorporada a la l√≠nea de productos oficial de la empresa (fusionada en la rama principal)...`?

```mermaid
flowchart TD
    A[Desarrollador Env√≠a PR] --> B{Verificaciones Automatizadas}
    B -->|Falla| C[Corregir Problemas]
    C --> A
    B -->|Pasa| D[Asignar Revisores]

    subgraph "Lado del Desarrollador"
      P1[Auto-verificaci√≥n del Desarrollador]
      P2[Ejecutar Pruebas Locales]
      P3[Formatear C√≥digo]
      P4[Confirmar Convenci√≥n de Mensajes de Commit]

      P1 --> P2
      P2 --> P3
      P3 --> P4
      P4 --> A
    end

    subgraph "Lado del Revisor"
      D[Asignar Revisores] --> E[Revisi√≥n del L√≠der T√©cnico]
      D --> F[Revisi√≥n del Ingeniero Senior]
      D --> G[Revisi√≥n del Product Owner]

      E --> H{Revisi√≥n T√©cnica Aprobada?}
      F --> I{Revisi√≥n de Calidad de C√≥digo Aprobada?}
      G --> J{Revisi√≥n de L√≥gica de Negocio Aprobada?}

      H -->|No| K[Solicitar Cambios]
      I -->|No| K
      J -->|No| K
      K --> A

      H -->|S√≠| L{Todas las Revisiones Aprobadas?}
      I -->|S√≠| L
      J -->|S√≠| L

      L -->|No| M[Esperando Otras Revisiones]
      L -->|S√≠| N[Aprobaci√≥n Final]
    end

    N --> O{Verificaci√≥n de Conflictos}
    O -->|Tiene Conflictos| P[Resolver Conflictos]
    P --> A
    O -->|Sin Conflictos| Q[Fusionar a Rama Destino]

    Q --> R[Auto-Despliegue]
    Q --> S[Notificar a Interesados]

    style A fill:#e3f2fd
    style Q fill:#e8f5e8
    style K fill:#ffebee
    style R fill:#f3e5f5
```

En este cap√≠tulo, mencionamos brevemente las **Verificaciones Automatizadas y el Auto-Despliegue (CI/CD)** en el diagrama de flujo. Sin embargo, en ese momento, no profundizamos en c√≥mo ejecutar este proceso, sino que nos centramos en analizar Git, o m√°s bien, la gesti√≥n de calidad por fases de los resultados del desarrollo. Pero en esta parte del proceso, podemos reducir el tiempo dedicado a cada env√≠o local y aplicar pasos como `pruebas funcionales en el entorno de lanzamiento`, `pruebas de integraci√≥n entre sistemas` y `pruebas e2e` a un entorno automatizado que se ejecuta de forma independiente para su detecci√≥n. Esta es una de las funciones principales de la **CI (Integraci√≥n Continua)**.

Este proceso elimina el costo de ejecutar pruebas localmente cada vez y minimiza las diferencias entre los entornos de desarrollo y lanzamiento tanto como sea posible (en mi experiencia de desarrollo, me he encontrado con situaciones en las que las pruebas fallaban localmente pero funcionaban bien en el lado del producto, y viceversa). Al mismo tiempo, cada Tarea y Trabajo ejecutado es tambi√©n una **protecci√≥n activa** de la **implementaci√≥n de la l√≥gica de negocio**. As√≠ que hoy, profundizaremos en c√≥mo construir un pipeline de automatizaci√≥n CI/CD a nivel empresarial a trav√©s de GitHub Actions, AWS CodePipeline y CodeBuild, con un enfoque especial en:

- **Gesti√≥n de Fragmentaci√≥n de Trabajos**: C√≥mo dividir y organizar razonablemente las tareas de CI/CD.
- **Gesti√≥n de Control de Versiones de Tareas**: C√≥mo controlar las versiones del proceso CI/CD.
- **Gesti√≥n de Abstracci√≥n de Par√°metros**: C√≥mo gestionar los par√°metros de configuraci√≥n para diferentes entornos.
- **Puerta de Revisi√≥n de Negocio**: C√≥mo a√±adir un mecanismo de revisi√≥n manual al proceso automatizado.

Primero, revisemos las dificultades del despliegue de software en la era pre-CI/CD:

**Escenario 1: El Miedo al Despliegue Manual**

```
Viernes, 5 PM...

Desarrollador: "Estoy a punto de desplegar la nueva caracter√≠stica en producci√≥n."
Colegas: "¬°Espera! ¬°No despliegues un viernes!"
Desarrollador: "¬øPor qu√©?"
Colegas: "Porque si algo sale mal, tendremos que trabajar horas extras durante el fin de semana..."

**Problemas Centrales**:
- El proceso de despliegue depende de operaciones manuales, propenso a errores.
- Falta de un proceso estandarizado, cada despliegue es un riesgo.
- Dif√≠cil de revertir, un problema tiene un gran impacto.
- El equipo carece de confianza en el despliegue.
```

**Escenario 2: El Desastre de Entornos Inconsistentes**

```
Desarrollador: "Extra√±o, funciona bien en mi m√°quina..."
Tester: "Pero hay un error en el entorno de pruebas."
Ingeniero de Operaciones: "Y el entorno de producci√≥n es diferente del entorno de pruebas..."
Gerente de Producto: "¬øCu√°ndo se puede arreglar? ¬°Los clientes est√°n esperando!"

**Problemas Centrales**:
- Configuraciones inconsistentes en los entornos de desarrollo, pruebas y producci√≥n.
- Gesti√≥n ca√≥tica de dependencias, frecuentes conflictos de versiones.
- Falta de pruebas automatizadas, los problemas se descubren demasiado tarde.
- Configuraci√≥n del entorno que consume mucho tiempo, afectando la eficiencia del desarrollo.
```

**Escenario 3: La Caja Negra del Proceso de Despliegue**

```
Nuevo Ingeniero: "¬øC√≥mo despliego mi c√≥digo?"
Ingeniero Senior: "Hmm... d√©jame pensar..."
"Primero, necesitas SSH en el servidor..."
"Luego git pull..."
"Luego recompilar..."
"Recuerda reiniciar nginx..."
"Y limpiar la cach√©..."
"Oh, y no olvides hacer una copia de seguridad de la base de datos..."

Novato: üòµ‚Äçüí´

**Problemas Centrales**:
- El conocimiento de despliegue se concentra en unas pocas personas.
- El proceso es complejo y carece de documentaci√≥n.
- Alto costo de aprendizaje para los nuevos miembros del equipo.
- Alto riesgo si el personal clave se va.
```

¬øHas notado que estos puntos d√©biles en la entrega de software son muy similares a los escenarios del cap√≠tulo <Infraestructura como C√≥digo: Codificando y Controlando Versiones de la Infraestructura con Terraform>? Cuando necesitamos probar y desplegar sin un **entorno estable** y un **proceso fijo de prueba de l√≥gica de negocio**, es f√°cil que el equipo de desarrollo sienta que camina sobre hielo delgado con cada despliegue. La raz√≥n m√°s importante por la que la **CI (Integraci√≥n Continua)** y la **CD (Despliegue/Entrega Continua)** son necesarias es para establecer un proceso estable y fijo de verificaci√≥n y entrega de l√≥gica de negocio, para **`proteger activamente la l√≥gica de negocio existente de ser corrompida por cambios en el c√≥digo`**.

## Conceptos Centrales y Valor de CI/CD

```
Proteger la l√≥gica de negocio existente de ser corrompida por cambios en el c√≥digo.
```

### ¬øQu√© es CI/CD?

**CI (Integraci√≥n Continua)**: Los desarrolladores fusionan frecuentemente los cambios de c√≥digo en la rama principal, y cada fusi√≥n desencadena un proceso automatizado de construcci√≥n y prueba.

**CD (Despliegue/Entrega Continua)**: A trav√©s de un proceso automatizado, el c√≥digo que ha pasado las pruebas se despliega autom√°ticamente en varios entornos, e incluso directamente en el entorno de producci√≥n.

### El Valor Central de CI/CD

```mermaid
graph TD
    A[Valor Central de CI/CD] --> B[Retroalimentaci√≥n R√°pida]
    A --> C[Reducci√≥n de Riesgos]
    A --> D[Aumento de Eficiencia]
    A --> E[Garant√≠a de Calidad]

    B --> B1[Detecci√≥n temprana de problemas]
    B --> B2[Correcci√≥n r√°pida de defectos]

    C --> C1[Lanzamientos en peque√±os lotes]
    C --> C2[Capacidad de reversi√≥n r√°pida]

    D --> D1[Automatizaci√≥n reemplaza el trabajo manual]
    D --> D2[Manejo de procesos paralelos]

    E --> E1[Cobertura de pruebas automatizadas]
    E --> E2[Entornos consistentes]
```

Imagina: `La transformaci√≥n de un "taller manual" a una "f√°brica automatizada".`

El desarrollo de software pasado era como un taller manual:

- **Hecho a mano**: Cada producto (versi√≥n de software) requer√≠a un artesano (desarrollador) para hacerlo a mano.
- **Calidad Inestable**: Depend√≠a de la habilidad y el estado del artesano ese d√≠a.
- **Producci√≥n Limitada**: Un artesano solo pod√≠a producir un n√∫mero limitado de productos por d√≠a.
- **Conocimiento Concentrado**: Las habilidades estaban en manos de unos pocos artesanos.

Y CI/CD es como construir una l√≠nea de producci√≥n automatizada:

- **Proceso Estandarizado**: Cada paso tiene est√°ndares claros y verificaciones automatizadas.
- **Garant√≠a de Calidad**: Cada producto pasa por el mismo proceso de inspecci√≥n de calidad.
- **Alta Eficiencia**: Las m√°quinas no se cansan y pueden trabajar 24/7.
- **Intercambio de Conocimiento**: El proceso est√° codificado, por lo que cualquiera puede entenderlo y mejorarlo.

## Pr√°ctica Profunda con GitHub Actions

GitHub Actions es una plataforma CI/CD proporcionada por GitHub que nos permite definir y ejecutar flujos de trabajo automatizados directamente en nuestro repositorio de c√≥digo.

### Conceptos Centrales de GitHub Actions

```mermaid
graph LR
    A[Arquitectura de GitHub Actions] --> B[Flujo de Trabajo]
    A --> C[Trabajo]
    A --> D[Paso]
    A --> E[Acci√≥n]

    B --> B1[.github/workflows/*.yml]
    B --> B2[Definici√≥n de condici√≥n de activaci√≥n]

    C --> C1[Selecci√≥n de entorno de ejecutor]
    C --> C2[Soporte de ejecuci√≥n paralela]

    D --> D1[Comandos de ejecuci√≥n espec√≠ficos]
    D --> D2[Configuraci√≥n de variables de entorno]

    E --> E1[Unidades de c√≥digo reutilizables]
    E --> E2[Ecosistema de Marketplace]
```

### Estrategia de Gesti√≥n de Fragmentaci√≥n de Trabajos

En un proceso CI/CD a nivel empresarial, la segmentaci√≥n razonable de los trabajos es crucial. Necesitamos equilibrar la eficiencia de ejecuci√≥n y la mantenibilidad:

#### 1. Principios B√°sicos de Segmentaci√≥n de Trabajos

```yaml
# .github/workflows/ci-cd.yml
name: "Pipeline CI/CD Frontend"

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  NODE_VERSION: "18"
  PNPM_VERSION: "8.15.0"

jobs:
  # Primera capa: Verificaciones b√°sicas (fallo r√°pido)
  code-quality:
    name: "Verificaci√≥n de Calidad de C√≥digo"
    runs-on: ubuntu-latest
    timeout-minutes: 10

    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Generar clave de cach√©
        id: cache-key
        run: |
          echo "key=node-${{ env.NODE_VERSION }}-${{ hashFiles('**/pnpm-lock.yaml') }}" >> $GITHUB_OUTPUT

      - name: Configurar Node.js y dependencias
        uses: ./.github/actions/setup-node
        with:
          node-version: ${{ env.NODE_VERSION }}
          pnpm-version: ${{ env.PNPM_VERSION }}
          cache-key: ${{ steps.cache-key.outputs.key }}

      - name: Verificaci√≥n de Lint y formato
        run: |
          pnpm run lint:check
          pnpm run format:check
          pnpm run type-check

  # Segunda capa: Ejecuci√≥n de pruebas (procesamiento paralelo)
  unit-tests:
    name: "Pruebas Unitarias"
    runs-on: ubuntu-latest
    needs: code-quality
    timeout-minutes: 15

    strategy:
      matrix:
        node-version: [16, 18, 20]

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Node.js y dependencias
        uses: ./.github/actions/setup-node
        with:
          node-version: ${{ matrix.node-version }}
          pnpm-version: ${{ env.PNPM_VERSION }}
          cache-key: ${{ needs.code-quality.outputs.cache-key }}

      - name: Ejecutar pruebas unitarias
        run: pnpm run test:unit --coverage

      - name: Subir cobertura
        if: matrix.node-version == '18'
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}

  integration-tests:
    name: "Pruebas de Integraci√≥n"
    runs-on: ubuntu-latest
    needs: code-quality
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Node.js y dependencias
        uses: ./.github/actions/setup-node
        with:
          node-version: ${{ env.NODE_VERSION }}
          pnpm-version: ${{ env.PNPM_VERSION }}
          cache-key: ${{ needs.code-quality.outputs.cache-key }}

      - name: Configurar base de datos de prueba
        run: |
          pnpm run db:migrate:test
          pnpm run db:seed:test
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db

      - name: Ejecutar pruebas de integraci√≥n
        run: pnpm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db

  e2e-tests:
    name: "Pruebas E2E"
    runs-on: ubuntu-latest
    needs: code-quality
    timeout-minutes: 30

    strategy:
      matrix:
        browser: [chromium, firefox]
        shard: [1/4, 2/4, 3/4, 4/4]

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Node.js y dependencias
        uses: ./.github/actions/setup-node
        with:
          node-version: ${{ env.NODE_VERSION }}
          pnpm-version: ${{ env.PNPM_VERSION }}
          cache-key: ${{ needs.code-quality.outputs.cache-key }}

      - name: Instalar Playwright
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Construir aplicaci√≥n
        run: pnpm run build:test

      - name: Ejecutar pruebas E2E
        run: |
          pnpm run start:test &
          npx wait-on http://localhost:3000
          npx playwright test --project=${{ matrix.browser }} --shard=${{ matrix.shard }}

      - name: Subir resultados de pruebas
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results-${{ matrix.browser }}-${{ matrix.shard }}
          path: playwright-report/

  # Tercera capa: Verificaciones de seguridad y calidad
  security-scan:
    name: "Escaneo de Seguridad"
    runs-on: ubuntu-latest
    needs: code-quality
    timeout-minutes: 15

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Ejecutar auditor√≠a de seguridad
        run: |
          npx audit-ci --config .audit-ci.json

      - name: Ejecutar escaneo SAST
        uses: github/super-linter@v4
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VALIDATE_JAVASCRIPT_ES: true
          VALIDATE_TYPESCRIPT_ES: true

      - name: Ejecutar esc√°ner de vulnerabilidades Trivy
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "sarif"
          output: "trivy-results.sarif"

      - name: Subir resultados del escaneo de seguridad
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-results.sarif"

  # Cuarta capa: Preparaci√≥n de construcci√≥n y despliegue
  build:
    name: "Construir Aplicaci√≥n"
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, security-scan]
    timeout-minutes: 10

    outputs:
      build-version: ${{ steps.version.outputs.version }}

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Generar versi√≥n
        id: version
        run: |
          VERSION=$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA:0:7}
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "::notice::Versi√≥n de construcci√≥n: $VERSION"

      - name: Configurar Node.js y dependencias
        uses: ./.github/actions/setup-node
        with:
          node-version: ${{ env.NODE_VERSION }}
          pnpm-version: ${{ env.PNPM_VERSION }}
          cache-key: ${{ needs.code-quality.outputs.cache-key }}

      - name: Construir aplicaci√≥n
        run: |
          pnpm run build
          echo ${{ steps.version.outputs.version }} > dist/version.txt
        env:
          VITE_BUILD_VERSION: ${{ steps.version.outputs.version }}
          VITE_BUILD_TIME: ${{ github.event.head_commit.timestamp }}
          VITE_COMMIT_SHA: ${{ github.sha }}

      - name: Validar construcci√≥n
        run: |
          # Verificar archivos clave
          test -f dist/index.html || { echo "‚ùå index.html no encontrado"; exit 1; }
          test -f dist/version.txt || { echo "‚ùå version.txt no encontrado"; exit 1; }

          # Verificar tama√±o de construcci√≥n
          BUNDLE_SIZE=$(du -sk dist | cut -f1)
          echo "Tama√±o del paquete: ${BUNDLE_SIZE}KB"

          if [ $BUNDLE_SIZE -gt 20480 ]; then
            echo "‚ö†Ô∏è Advertencia de tama√±o de paquete: ${BUNDLE_SIZE}KB > 20MB"
          fi

      - name: Subir artefactos de construcci√≥n
        uses: actions/upload-artifact@v4
        with:
          name: build-${{ steps.version.outputs.version }}
          path: dist/
          retention-days: 7

  # Quinta capa: Desplegar en entorno de staging
  deploy-staging:
    name: "Desplegar en Staging"
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop'
    timeout-minutes: 10

    environment:
      name: staging
      url: https://staging.myapp.com

    steps:
      - name: Descargar artefactos de construcci√≥n
        uses: actions/download-artifact@v4
        with:
          name: build-${{ needs.build.outputs.build-version }}
          path: dist/

      - name: Configurar credenciales de AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: Desplegar en S3
        run: |
          aws s3 sync dist/ s3://${{ secrets.STAGING_S3_BUCKET }} --delete
          aws cloudfront create-invalidation --distribution-id ${{ secrets.STAGING_CLOUDFRONT_ID }} --paths "/*"

      - name: Ejecutar verificaci√≥n de despliegue
        run: |
          sleep 30
          HTTP_CODE=$(curl -s -o /dev/null -w "%{{http_code}}" https://staging.myapp.com)
          if [ $HTTP_CODE -ne 200 ]; then
            echo "‚ùå Verificaci√≥n de despliegue fallida (HTTP $HTTP_CODE)"
            exit 1
          fi
          echo "‚úÖ Despliegue en Staging verificado"

  # Sexta capa: Puerta de revisi√≥n de negocio
  approval-gate:
    name: "Aprobaci√≥n de Producci√≥n"
    runs-on: ubuntu-latest
    needs: [build, deploy-staging]
    if: github.ref == 'refs/heads/main'
    timeout-minutes: 1440 # 24 horas de tiempo de espera

    environment:
      name: production-approval

    steps:
      - name: Solicitar aprobaci√≥n de despliegue en producci√≥n
        run: |
          echo "üîç Aprobaci√≥n de despliegue en producci√≥n solicitada"
          echo "üìã Versi√≥n de construcci√≥n: ${{ needs.build.outputs.build-version }}"
          echo "üåê URL de Staging: https://staging.myapp.com"
          echo "‚è∞ Tiempo de espera de aprobaci√≥n: 24 horas"

  # S√©ptima capa: Despliegue en producci√≥n
  deploy-production:
    name: "Desplegar en Producci√≥n"
    runs-on: ubuntu-latest
    needs: [build, approval-gate]
    timeout-minutes: 15

    environment:
      name: production
      url: https://myapp.com

    steps:
      - name: Descargar artefactos de construcci√≥n
        uses: actions/download-artifact@v4
        with:
          name: build-${{ needs.build.outputs.build-version }}
          path: dist/

      - name: Configurar credenciales de AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: Hacer copia de seguridad de la versi√≥n actual
        run: |
          BACKUP_TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          aws s3 sync s3://${{ secrets.PRODUCTION_S3_BUCKET }} s3://${{ secrets.BACKUP_S3_BUCKET }}/${BACKUP_TIMESTAMP}/
          echo "BACKUP_PATH=${BACKUP_TIMESTAMP}" >> $GITHUB_ENV

      - name: Desplegar en producci√≥n
        run: |
          aws s3 sync dist/ s3://${{ secrets.PRODUCTION_S3_BUCKET }} --delete
          aws cloudfront create-invalidation --distribution-id ${{ secrets.PRODUCTION_CLOUDFRONT_ID }} --paths "/*"

      - name: Verificaci√≥n de salud de producci√≥n
        run: |
          echo "Esperando propagaci√≥n de CDN..."
          sleep 60

          for i in {1..5};
          do
            HTTP_CODE=$(curl -s -o /dev/null -w "%{{http_code}}" https://myapp.com)
            if [ $HTTP_CODE -eq 200 ]; then
              echo "‚úÖ Verificaci√≥n de salud de producci√≥n aprobada (intento $i)"
              break
            elif [ $i -eq 5 ]; then
              echo "‚ùå Verificaci√≥n de salud de producci√≥n fallida despu√©s de 5 intentos"
              echo "üîÑ Revirtiendo..."
              aws s3 sync s3://${{ secrets.BACKUP_S3_BUCKET }}/${{ env.BACKUP_PATH }}/ s3://${{ secrets.PRODUCTION_S3_BUCKET }} --delete
              aws cloudfront create-invalidation --distribution-id ${{ secrets.PRODUCTION_CLOUDFRONT_ID }} --paths "/*"
              exit 1
            else
              echo "‚è≥ Intento de verificaci√≥n de salud $i fallido, reintentando..."
              sleep 30
            fi
          done

      - name: Notificar √©xito del despliegue
        if: success()
        uses: 8398a7/action-slack@v3
        with:
          status: success
          channel: "#deployment"
          text: |
            üöÄ ¬°Despliegue en producci√≥n exitoso!
            üì¶ Versi√≥n: ${{ needs.build.outputs.build-version }}
            üåê URL: https://myapp.com
            üë§ Desplegado por: ${{ github.actor }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notificar fallo del despliegue
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: "#deployment"
          text: |
            ‚ùå ¬°Despliegue en producci√≥n fallido!
            üì¶ Versi√≥n: ${{ needs.build.outputs.build-version }}
            üîÑ Reversi√≥n autom√°tica iniciada
            üë§ Intentado por: ${{ github.actor }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

#### 2. Modularizaci√≥n de Trabajos a Nivel Empresarial y Referencia Cruzada de Dominios

Adem√°s de dividir los trabajos dentro de un √∫nico archivo de flujo de trabajo, para est√°ndares compartidos a nivel empresarial y mantenibilidad, podemos separar los trabajos que pertenecen a un dominio o funci√≥n espec√≠fica en diferentes flujos de trabajo reutilizables. Cuando sea necesario, el flujo de trabajo principal puede referenciar y ejecutar estos trabajos independientes como una biblioteca.

La mayor ventaja de este enfoque es que permite que la l√≥gica de interacci√≥n de dominio entre diferentes sistemas se valide mutuamente. Por ejemplo, cuando se actualiza el proceso CI del `user-service`, el proceso CI del `order-service` puede asegurar que este cambio no ha roto las funciones relacionadas con el usuario en el proceso de pedido al referenciar el trabajo de prueba del `user-service`. Esto evita el dilema de "est√° bien en mi dominio, pero afecta a otros dominios".

**Escenario: Un cambio en el Servicio de Usuario necesita asegurar que el Servicio de Pedidos no se vea afectado.**

Primero, definimos un flujo de trabajo CI reutilizable para el `user-service`, que incluye un trabajo espec√≠ficamente para validar funciones centrales.

```yaml
# .github/workflows/reusable-user-service-ci.yml
name: "CI Reutilizable del Servicio de Usuario"

on:
  workflow_call:
    inputs:
      node-version:
        required: false
        type: string
        default: "18"
    outputs:
      test-results-summary:
        description: "Un resumen de los resultados de las pruebas del servicio de usuario"
        value: ${{ jobs.validate-user-core.outputs.summary }}

jobs:
  validate-user-core:
    name: "Validar L√≥gica Central del Servicio de Usuario"
    runs-on: ubuntu-latest
    outputs:
      summary: ${{ steps.test-summary.outputs.summary }}

    steps:
      - name: Checkout del c√≥digo del Servicio de Usuario
        uses: actions/checkout@v4
        with:
          repository: "my-org/user-service"
          ref: "main"

      # ... (Configurar Node.js, instalar dependencias) ...

      - name: Ejecutar pruebas centrales del servicio de usuario
        id: core-tests
        run: |
          # Ejecutar pruebas de integraci√≥n para funciones centrales
          pnpm run test:core-integration
          echo "summary=L√≥gica central del usuario validada exitosamente" >> $GITHUB_OUTPUT

      - name: Crear resumen de pruebas
        id: test-summary
        run: echo "summary=‚úÖ Validaci√≥n central del Servicio de Usuario aprobada" >> $GITHUB_OUTPUT
```

Luego, en el flujo de trabajo CI/CD principal del `order-service`, podemos referenciar el trabajo anterior para la validaci√≥n de integraci√≥n entre dominios.

```yaml
# .github/workflows/order-service-ci.yml
name: "CI/CD del Servicio de Pedidos"

on:
  push:
    branches: [main]
  pull_request:

jobs:
  # Ejecutar las propias pruebas del servicio de pedidos
  test-order-service:
    name: "Probar Servicio de Pedidos"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del c√≥digo del Servicio de Pedidos
        uses: actions/checkout@v4
      # ... (Ejecutar las propias pruebas del servicio de pedidos) ...
      - name: Ejecutar pruebas de pedidos
        run: pnpm run test

  # Referenciar el trabajo CI del Servicio de Usuario para validaci√≥n de integraci√≥n
  cross-validate-with-user-service:
    name: "Validaci√≥n Cruzada de Dominio (Servicio de Usuario)"
    needs: test-order-service
    uses: ./.github/workflows/reusable-user-service-ci.yml
    with:
      node-version: "18"

  # Construir solo despu√©s de que sus propias pruebas y la validaci√≥n cruzada de dominio hayan pasado
  build:
    name: "Construir Servicio de Pedidos"
    runs-on: ubuntu-latest
    needs: [test-order-service, cross-validate-with-user-service]
    steps:
      - name: Mostrar resultados de validaci√≥n
        run: |
          echo "Las pruebas del Servicio de Pedidos pasaron."
          echo "Resumen de validaci√≥n del Servicio de Usuario: ${{ needs.cross-validate-with-user-service.outputs.test-results-summary }}"
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4
      # ... (Pasos de construcci√≥n) ...
      - name: Construir aplicaci√≥n
        run: pnpm run build
```

Por supuesto, si desea reducir la granularidad al nivel de `Step`, tambi√©n es factible.

```yaml
steps:
  - task: SonarCloudAnalyze@3
    inputs:
      jdkversion: "JAVA_HOME_21_X64"
    condition: succeededOrFailed()
  - task: SonarCloudPublish@3
    inputs:
      pollingTimeoutSec: "300"
    condition: succeededOrFailed()
```

A trav√©s de este enfoque, elevamos la tarea de CI/CD de "garant√≠a de calidad para un solo proyecto" a "protecci√≥n de la estabilidad del sistema en proyectos y dominios", lo cual es crucial en arquitecturas de microservicios o sistemas complejos.

#### 3. Creaci√≥n de Acciones Reutilizables

Para mejorar la reutilizaci√≥n del c√≥digo, creamos acciones personalizadas:

```yaml
# .github/actions/setup-node/action.yml
name: "Configurar Entorno Node.js"
description: "Configurar Node.js con pnpm y cach√© de dependencias"

inputs:
  node-version:
    description: "Versi√≥n de Node.js"
    required: true
    default: "18"
  pnpm-version:
    description: "Versi√≥n de pnpm"
    required: true
    default: "8.15.0"
  cache-key:
    description: "Clave de cach√© para dependencias"
    required: true

runs:
  using: "composite"
  steps:
    - name: Configurar Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ inputs.node-version }}

    - name: Configurar pnpm
      uses: pnpm/action-setup@v3
      with:
        version: ${{ inputs.pnpm-version }}

    - name: Obtener directorio de la tienda pnpm
      id: pnpm-cache
      shell: bash
      run: echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

    - name: Configurar cach√© de pnpm
      uses: actions/cache@v4
      with:
        path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}
        key: ${{ inputs.cache-key }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    - name: Instalar dependencias
      shell: bash
      run: pnpm install --frozen-lockfile
```

### Estrategia de Gesti√≥n de Control de Versiones de Tareas

#### 1. Configuraci√≥n de Versionado de Flujos de Trabajo

```yaml
# .github/workflows/ci-cd-v2.yml
name: "Pipeline CI/CD v2.0"

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      workflow-version:
        required: false
        type: string
        default: "v2.0"

env:
  WORKFLOW_VERSION: ${{ inputs.workflow-version }}
  TARGET_ENVIRONMENT: ${{ inputs.environment }}

jobs:
  version-check:
    name: "Verificaci√≥n de Versi√≥n del Flujo de Trabajo"
    runs-on: ubuntu-latest

    steps:
      - name: Validar versi√≥n del flujo de trabajo
        run: |
          echo "üîÑ Ejecutando Pipeline CI/CD ${{ env.WORKFLOW_VERSION }}"
          echo "üéØ Entorno Objetivo: ${{ env.TARGET_ENVIRONMENT }}"

          # Verificaci√≥n de compatibilidad de versiones
          case "${{ env.WORKFLOW_VERSION }}" in
            v1.*)
              echo "‚ö†Ô∏è Usando versi√≥n de flujo de trabajo heredada"
              ;;;
            v2.*)
              echo "‚úÖ Usando versi√≥n actual de flujo de trabajo"
              ;;;
            *)
              echo "‚ùå Versi√≥n de flujo de trabajo desconocida"
              exit 1
              ;;;
          esac
```

#### 2. Gesti√≥n de Archivos de Configuraci√≥n de Pipeline

```yaml
# .github/pipeline-configs/production.yml
version: "2.0"
environment: "production"

stages:
  code-quality:
    enabled: true
    timeout: 10
    node-versions: [18, 20]

  testing:
    unit-tests:
      enabled: true
      timeout: 15
      parallel-matrix: true
    integration-tests:
      enabled: true
      timeout: 20
      services: [postgres, redis]
    e2e-tests:
      enabled: true
      timeout: 30
      browsers: [chromium, firefox]
      sharding: 4

  security:
    audit: true
    sast: true
    vulnerability-scan: true

  deployment:
    strategy: "blue-green"
    health-check:
      enabled: true
      retries: 5
      interval: 30
    rollback:
      auto: true
      timeout: 300

  notifications:
    slack:
      success: "#deployment"
      failure: "#alerts"
    email:
      - devops@company.com
```

#### 3. Carga Din√°mica de Pipeline

```yaml
# .github/workflows/dynamic-pipeline.yml
name: "Cargador Din√°mico de Pipeline"

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  load-config:
    name: "Cargar Configuraci√≥n de Pipeline"
    runs-on: ubuntu-latest

    outputs:
      config: ${{ steps.config.outputs.config }}
      version: ${{ steps.config.outputs.version }}

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Cargar configuraci√≥n de pipeline
        id: config
        run: |
          # Seleccionar archivo de configuraci√≥n basado en la rama
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            CONFIG_FILE=".github/pipeline-configs/production.yml"
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            CONFIG_FILE=".github/pipeline-configs/staging.yml"
          else
            CONFIG_FILE=".github/pipeline-configs/development.yml"
          fi

          # Cargar y mostrar configuraci√≥n
          CONFIG=$(cat $CONFIG_FILE | yq -o=json)
          VERSION=$(echo $CONFIG | jq -r '.version')

          echo "config=$CONFIG" >> $GITHUB_OUTPUT
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "üìÑ Configuraci√≥n cargada desde: $CONFIG_FILE"
          echo "üè∑Ô∏è Versi√≥n de Pipeline: $VERSION"

  execute-pipeline:
    name: "Ejecutar Pipeline"
    needs: load-config
    uses: ./.github/workflows/ci-cd-v2.yml
    with:
      environment: ${{ fromJson(needs.load-config.outputs.config).environment }}
      workflow-version: ${{ needs.load-config.outputs.version }}
    secrets: inherit
```

#### 4. Control de Versiones para Flujos de Trabajo Reutilizables entre Dominios

Cuando modularizamos trabajos en flujos de trabajo reutilizables (como `reusable-user-service-ci.yml`), el control de versiones de estos flujos de trabajo compartidos se vuelve crucial. Esto asegura que cuando el proceso CI de un servicio central (como `user-service`) cambia, no rompa accidentalmente el proceso de construcci√≥n de otros servicios que dependen de √©l (como `order-service`).

**Escenario: El proceso CI para `user-service` se actualiza de v1 a v2, pero `order-service` necesita temporalmente seguir usando v1.**

Podemos usar etiquetas de Git para controlar las versiones de los flujos de trabajo reutilizables.

Primero, el archivo `reusable-user-service-ci.yml` para el propio `user-service` no necesita una etiqueta de versi√≥n especial. Su versi√≥n se gestiona mediante las etiquetas del repositorio de Git en el que reside. Cuando creemos que `reusable-user-service-ci.yml` ha alcanzado un estado estable, creamos una etiqueta de versi√≥n en ese commit, por ejemplo, `v1.0` o `v2.0`.

Luego, en el flujo de trabajo CI de `order-service`, podemos especificar expl√≠citamente la versi√≥n del CI de `user-service` a usar.

```yaml
# .github/workflows/order-service-ci.yml
name: "CI/CD del Servicio de Pedidos"

on:
  push:
    branches: [main]
  pull_request:

jobs:
  test-order-service:
    # ... (Ejecutar las propias pruebas del servicio de pedidos) ...
    name: "Probar Servicio de Pedidos"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del c√≥digo del Servicio de Pedidos
        uses: actions/checkout@v4
      - name: Ejecutar pruebas de pedidos
        run: pnpm run test

  # Referenciar la v1.0 del CI del Servicio de Usuario para validaci√≥n
  cross-validate-with-user-service-v1:
    name: "Validaci√≥n Cruzada de Dominio (Servicio de Usuario @v1.0)"
    needs: test-order-service
    # Usar la sintaxis @<tag> para bloquear la versi√≥n del flujo de trabajo reutilizable
    uses: my-org/user-service/.github/workflows/reusable-user-service-ci.yml@v1.0
    with:
      node-version: "18"

  # Cuando el equipo est√© listo, se puede crear un nuevo PR para actualizar a v2.0
  # cross-validate-with-user-service-v2:
  #   name: "Validaci√≥n Cruzada de Dominio (Servicio de Usuario @v2.0)"
  #   needs: test-order-service
  #   uses: my-org/user-service/.github/workflows/reusable-user-service-ci.yml@v2.0
  #   with:
  #     node-version: '20'

  build:
    name: "Construir Servicio de Pedidos"
    runs-on: ubuntu-latest
    needs: [test-order-service, cross-validate-with-user-service-v1]
    steps:
      - name: Mostrar resultados de validaci√≥n
        run: |
          echo "Las pruebas del Servicio de Pedidos pasaron."
          echo "Resumen de validaci√≥n del Servicio de Usuario: ${{ needs.cross-validate-with-user-service-v1.outputs.test-results-summary }}"
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4
      - name: Construir aplicaci√≥n
        run: pnpm run build
```

Esta estrategia extiende el concepto de "Control de Versiones de Tareas" desde dentro de un solo proyecto a una dimensi√≥n a nivel empresarial a trav√©s de proyectos y servicios, logrando una verdadera gesti√≥n versionada de Pipeline as Code.

### Estrategia de Gesti√≥n de Abstracci√≥n de Par√°metros

#### 1. Gesti√≥n por Capas de Variables de Entorno

```yaml
# .github/environments/production.yml
variables:
  # Variables p√∫blicas
  NODE_ENV: "production"
  API_VERSION: "v2"
  BUILD_TARGET: "production"
  CACHE_TTL: "3600"

  # Configuraci√≥n de CDN
  CDN_DOMAIN: "cdn.myapp.com"
  ASSET_PREFIX: "/static"

  # Banderas de caracter√≠sticas
  FEATURE_NEW_UI: "true"
  FEATURE_ANALYTICS: "true"
  FEATURE_AB_TESTING: "true"

secrets:
  # Informaci√≥n sensible (debe configurarse en GitHub Secrets)
  - AWS_ACCESS_KEY_ID
  - AWS_SECRET_ACCESS_KEY
  - SENTRY_DSN
  - ANALYTICS_API_KEY
  - DATABASE_CONNECTION_STRING
```

#### 2. Inyecci√≥n Din√°mica de Variables de Entorno

```yaml
# .github/workflows/env-management.yml
name: "Gesti√≥n de Entorno"

jobs:
  setup-environment:
    name: "Configurar Variables de Entorno"
    runs-on: ubuntu-latest

    outputs:
      env-config: ${{ steps.env-setup.outputs.config }}

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Configurar entorno
        id: env-setup
        run: |
          # Cargar configuraci√≥n basada en el entorno objetivo
          case "${{ github.ref }}" in
            refs/heads/main)
              ENV_FILE=".github/environments/production.yml"
              ;;;
            refs/heads/develop)
              ENV_FILE=".github/environments/staging.yml"
              ;;;
            *)
              ENV_FILE=".github/environments/development.yml"
              ;;;
          esac

          # Cargar variables de entorno
          ENV_VARS=$(yq '.variables' $ENV_FILE)

          # Salida en formato JSON
          echo "config=$ENV_VARS" >> $GITHUB_OUTPUT

          # Establecer variables de entorno para el trabajo actual
          yq '.variables | to_entries | .[] | "\(.key)=\(.value)"' $ENV_FILE >> $GITHUB_ENV

  build-with-env:
    name: "Construir con Entorno"
    needs: setup-environment
    runs-on: ubuntu-latest

    steps:
      - name: Checkout del c√≥digo
        uses: actions/checkout@v4

      - name: Aplicar configuraci√≥n de entorno
        run: |
          # Obtener configuraci√≥n de entorno del trabajo anterior
          ENV_CONFIG='${{ needs.setup-environment.outputs.env-config }}'
          echo "$ENV_CONFIG" | jq -r 'to_entries | .[] | "\(.key)=\(.value)"' >> $GITHUB_ENV

      - name: Construir aplicaci√≥n
        run: |
          echo "üèóÔ∏è Construyendo con entorno: $NODE_ENV"
          echo "üåê Versi√≥n de API: $API_VERSION"
          echo "üéØ Objetivo de Construcci√≥n: $BUILD_TARGET"

          # Crear archivo de informaci√≥n de construcci√≥n
          cat > build-info.json << EOF
          {
            "environment": "$NODE_ENV",
            "apiVersion": "$API_VERSION",
            "buildTarget": "$BUILD_TARGET",
            "buildTime": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "gitCommit": "$GITHUB_SHA",
            "gitBranch": "$GITHUB_REF_NAME"
          }
          EOF

          # Ejecutar construcci√≥n
          npm run build
```

#### 3. Gesti√≥n Segura de Par√°metros Secretos

```yaml
# .github/workflows/secrets-management.yml
name: "Gesti√≥n de Secretos"

jobs:
  validate-secrets:
    name: "Validar Secretos Requeridos"
    runs-on: ubuntu-latest

    steps:
      - name: Verificar secretos requeridos
        env:
          # Referenciar los secretos requeridos
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SENTRY_DSN: ${{ secrets.SENTRY_DSN }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

        run: |
          # Validar que existan los secretos necesarios
          MISSING_SECRETS=()

          [ -z "$AWS_ACCESS_KEY_ID" ] && MISSING_SECRETS+=("AWS_ACCESS_KEY_ID")
          [ -z "$AWS_SECRET_ACCESS_KEY" ] && MISSING_SECRETS+=("AWS_SECRET_ACCESS_KEY")
          [ -z "$SENTRY_DSN" ] && MISSING_SECRETS+=("SENTRY_DSN")
          [ -z "$SLACK_WEBHOOK_URL" ] && MISSING_SECRETS+=("SLACK_WEBHOOK_URL")

          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "‚ùå Secretos requeridos faltantes:"
            printf "  - %s\n" "${MISSING_SECRETS[@]}"
            exit 1
          fi

          echo "‚úÖ Todos los secretos requeridos est√°n disponibles"

      - name: Probar credenciales de AWS
        run: |
          # Probar validez de credenciales de AWS
          aws sts get-caller-identity || {
            echo "‚ùå Las credenciales de AWS no son v√°lidas"
            exit 1
          }
          echo "‚úÖ Las credenciales de AWS son v√°lidas"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ap-northeast-1
```

## Integraci√≥n a Nivel Empresarial con AWS CodePipeline y CodeBuild

Para entornos empresariales grandes, necesitamos una infraestructura CI/CD m√°s potente. AWS CodePipeline proporciona caracter√≠sticas m√°s completas a nivel empresarial.

### Dise√±o Completo del Proceso de CodePipeline

```yaml
# infrastructure/codepipeline.tf
resource "aws_codepipeline" "main" {
  name     = "${var.project_name}-pipeline"
  role_arn = aws_iam_role.codepipeline_role.arn

  artifact_store {
    location = aws_s3_bucket.pipeline_artifacts.bucket
    type     = "S3"

    encryption_key {
      id   = aws_kms_key.pipeline_key.arn
      type = "KMS"
    }
  }

  # Etapa 1: Fuente
  stage {
    name = "Source"

    action {
      name             = "SourceAction"
      category         = "Source"
      owner            = "ThirdParty"
      provider         = "GitHub"
      version          = "1"
      output_artifacts = ["source_output"]

      configuration = {
        Owner  = var.github_owner
        Repo   = var.github_repo
        Branch = var.github_branch
        OAuthToken = var.github_token
        PollForSourceChanges = false
      }
    }
  }

  # Etapa 2: Calidad de C√≥digo
  stage {
    name = "CodeQuality"

    action {
      name             = "LintAndFormat"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["quality_output"]

      configuration = {
        ProjectName = aws_codebuild_project.code_quality.name
      }
    }

    action {
      name             = "SecurityScan"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["security_output"]

      configuration = {
        ProjectName = aws_codebuild_project.security_scan.name
      }

      run_order = 2
    }
  }

  # Etapa 3: Pruebas
  stage {
    name = "Testing"

    action {
      name             = "UnitTests"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["unit_test_output"]

      configuration = {
        ProjectName = aws_codebuild_project.unit_tests.name
      }
    }

    action {
      name             = "IntegrationTests"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["integration_test_output"]

      configuration = {
        ProjectName = aws_codebuild_project.integration_tests.name
      }

      run_order = 2
    }

    action {
      name             = "E2ETests"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["e2e_test_output"]

      configuration = {
        ProjectName = aws_codebuild_project.e2e_tests.name
      }

      run_order = 3
    }
  }

  # Etapa 4: Construcci√≥n
  stage {
    name = "Build"

    action {
      name             = "BuildApplication"
      category         = "Build"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]
      output_artifacts = ["build_output"]

      configuration = {
        ProjectName = aws_codebuild_project.build.name
        EnvironmentVariables = jsonencode([
          {
            name  = "ENVIRONMENT"
            value = "staging"
          },
          {
            name  = "BUILD_NUMBER"
            value = "#{codepipeline.PipelineExecutionId}"
          },
          {
            name  = "COMMIT_SHA"
            value = "#{SourceVariables.CommitId}"
          }
        ])
      }
    }
  }

  # Etapa 5: Desplegar en Staging
  stage {
    name = "DeployStaging"

    action {
      name            = "DeployToS3"
      category        = "Deploy"
      owner           = "AWS"
      provider        = "S3"
      version         = "1"
      input_artifacts = ["build_output"]

      configuration = {
        BucketName = aws_s3_bucket.staging.bucket
        Extract    = "true"
      }
    }

    action {
      name             = "InvalidateCloudFront"
      category         = "Invoke"
      owner            = "AWS"
      provider         = "Lambda"
      version          = "1"

      configuration = {
        FunctionName = aws_lambda_function.invalidate_cache.function_name
        UserParameters = jsonencode({
          distribution_id = aws_cloudfront_distribution.staging.id
          paths = ["/*"]
        })
      }

      run_order = 2
    }

    action {
      name             = "StagingTests"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]

      configuration = {
        ProjectName = aws_codebuild_project.staging_tests.name
        EnvironmentVariables = jsonencode([
          {
            name  = "TEST_URL"
            value = "https://${aws_cloudfront_distribution.staging.domain_name}"
          }
        ])
      }

      run_order = 3
    }
  }

  # Etapa 6: Aprobaci√≥n de Negocio
  stage {
    name = "ApprovalGate"

    action {
      name     = "ProductionApproval"
      category = "Approval"
      owner    = "AWS"
      provider = "Manual"
      version  = "1"

      configuration = {
        NotificationArn    = aws_sns_topic.deployment_approval.arn
        CustomData         = "Por favor, revise el despliegue en staging y apruebe para producci√≥n. URL de Staging: https://${aws_cloudfront_distribution.staging.domain_name}"
        ExternalEntityLink = "https://${aws_cloudfront_distribution.staging.domain_name}"
      }
    }
  }

  # Etapa 7: Desplegar en Producci√≥n
  stage {
    name = "DeployProduction"

    action {
      name             = "BackupProduction"
      category         = "Invoke"
      owner            = "AWS"
      provider         = "Lambda"
      version          = "1"

      configuration = {
        FunctionName = aws_lambda_function.backup_production.function_name
        UserParameters = jsonencode({
          source_bucket = aws_s3_bucket.production.bucket
          backup_bucket = aws_s3_bucket.backup.bucket
          timestamp = "#{codepipeline.PipelineExecutionId}"
        })
      }
    }

    action {
      name             = "DeployToProduction"
      category         = "Deploy"
      owner            = "AWS"
      provider         = "S3"
      version          = "1"
      input_artifacts = ["build_output"]

      configuration = {
        BucketName = aws_s3_bucket.production.bucket
        Extract    = "true"
      }

      run_order = 2
    }

    action {
      name             = "InvalidateProductionCache"
      category         = "Invoke"
      owner            = "AWS"
      provider         = "Lambda"
      version          = "1"

      configuration = {
        FunctionName = aws_lambda_function.invalidate_cache.function_name
        UserParameters = jsonencode({
          distribution_id = aws_cloudfront_distribution.production.id
          paths = ["/*"]
        })
      }

      run_order = 3
    }

    action {
      name             = "ProductionHealthCheck"
      category         = "Invoke"
      owner            = "AWS"
      provider         = "Lambda"
      version          = "1"

      configuration = {
        FunctionName = aws_lambda_function.health_check.function_name
        UserParameters = jsonencode({
          url = "https://${aws_cloudfront_distribution.production.domain_name}"
          retries = 5
          interval = 30
        })
      }

      run_order = 4
    }
  }

  # Etapa 8: Verificaci√≥n Post-Despliegue
  stage {
    name = "PostDeployment"

    action {
      name             = "ProductionTests"
      category         = "Test"
      owner            = "AWS"
      provider         = "CodeBuild"
      version          = "1"
      input_artifacts  = ["source_output"]

      configuration = {
        ProjectName = aws_codebuild_project.production_tests.name
        EnvironmentVariables = jsonencode([
          {
            name  = "TEST_URL"
            value = "https://${aws_cloudfront_distribution.production.domain_name}"
          }
        ])
      }
    }

    action {
      name             = "NotifySuccess"
      category         = "Invoke"
      owner            = "AWS"
      provider         = "Lambda"
      version          = "1"

      configuration = {
        FunctionName = aws_lambda_function.notify_deployment.function_name
        UserParameters = jsonencode({
          status = "success"
          pipeline_execution_id = "#{codepipeline.PipelineExecutionId}"
          commit_id = "#{SourceVariables.CommitId}"
        })
      }

      run_order = 2
    }
  }

  tags = var.tags
}

# Manejo de fallos de pipeline
resource "aws_cloudwatch_event_rule" "pipeline_failure" {
  name = "${var.project_name}-pipeline-failure"

  event_pattern = jsonencode({
    source      = ["aws.codepipeline"]
    detail-type = ["CodePipeline Pipeline Execution State Change"]
    detail = {
      state = ["FAILED"]
      pipeline = [aws_codepipeline.main.name]
    }
  })
}

resource "aws_cloudwatch_event_target" "pipeline_failure_lambda" {
  rule      = aws_cloudwatch_event_rule.pipeline_failure.name
  target_id = "PipelineFailureLambdaTarget"
  arn       = aws_lambda_function.handle_pipeline_failure.arn
}
```

### Configuraci√≥n Avanzada del Proyecto CodeBuild

#### 1. Proyecto de Construcci√≥n Multi-etapa

```yaml
# buildspec/multi-stage-build.yml
version: 0.2

phases:
  install:
    runtime-versions:
      nodejs: 18
      python: 3.9
      docker: 20
    commands:
      - echo "üöÄ Iniciando proceso de construcci√≥n multi-etapa"
      - echo "üì¶ Instalando dependencias de construcci√≥n..."

      # Instalar herramientas relacionadas con Node.js
      - npm install -g pnpm@8.15.0
      - npm install -g npm-check-updates

      # Instalar herramientas relacionadas con Python
      - pip install --upgrade pip
      - pip install boto3 requests

      # Instalar otras herramientas
      - curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin

  pre_build:
    commands:
      - echo "üîç Validaci√≥n previa a la construcci√≥n iniciada"

      # Validaci√≥n de variables de entorno
      - |
        REQUIRED_VARS=("ENVIRONMENT" "BUILD_NUMBER" "COMMIT_SHA")
        for var in "${REQUIRED_VARS[@]}"; do
          if [ -z "${!var}" ]; then
            echo "‚ùå La variable de entorno requerida $var no est√° configurada"
            exit 1
          fi
        done
        echo "‚úÖ Todas las variables de entorno requeridas est√°n configuradas"

      # Instalaci√≥n y cach√© de dependencias
      - echo "üì¶ Instalando dependencias..."
      - pnpm install --frozen-lockfile

      # Verificaci√≥n de seguridad de dependencias
      - echo "üîí Ejecutando auditor√≠a de seguridad de dependencias..."
      - pnpm audit --audit-level=moderate

      # Generar informaci√≥n de construcci√≥n
      - |
        BUILD_INFO=$(cat << EOF
        {
          "buildNumber": "$BUILD_NUMBER",
          "environment": "$ENVIRONMENT",
          "commitSha": "$COMMIT_SHA",
          "buildTime": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "nodeVersion": "$(node --version)",
          "pnpmVersion": "$(pnpm --version)",
          "platform": "$(uname -a)"
        }
        EOF
        )
        echo "$BUILD_INFO" > build-info.json
        echo "üìÑ Informaci√≥n de construcci√≥n generada"

  build:
    commands:
      - echo "üèóÔ∏è Fase de construcci√≥n iniciada"

      # Verificaciones de calidad de c√≥digo
      - echo "üîç Ejecutando verificaciones de calidad de c√≥digo..."
      - pnpm run lint:check
      - pnpm run format:check
      - pnpm run type-check

      # Pruebas unitarias
      - echo "üß™ Ejecutando pruebas unitarias..."
      - pnpm run test:unit --coverage --reporter=junit --outputFile=test-results.xml

      # Construir aplicaci√≥n
      - echo "üì¶ Construyendo aplicaci√≥n..."
      - pnpm run build

      # Validaci√≥n post-construcci√≥n
      - echo "‚úÖ Validaci√≥n post-construcci√≥n..."
      - |
        # Verificar archivos de construcci√≥n
        if [ ! -f "dist/index.html" ]; then
          echo "‚ùå Archivo de entrada principal no encontrado"
          exit 1
        fi

        # Verificar tama√±o de construcci√≥n
        BUNDLE_SIZE=$(du -sk dist | cut -f1)
        echo "üìä Tama√±o del paquete: ${BUNDLE_SIZE}KB"

        if [ $BUNDLE_SIZE -gt 51200 ]; then  # 50MB
          echo "‚ö†Ô∏è El tama√±o del paquete es grande: ${BUNDLE_SIZE}KB"
        fi

        # Verificar recursos clave
        ASSET_COUNT=$(find dist -name "*.js" -o -name "*.css" | wc -l)
        echo "üìÑ Activos generados: $ASSET_COUNT archivos"

      # Generar SBOM (Lista de Materiales de Software)
      - echo "üìã Generando SBOM..."
      - syft packages dir:. -o spdx-json > sbom.spdx.json

      # Construir imagen Docker (si es necesario)
      - |
        if [ -f "Dockerfile" ]; then
          echo "üê≥ Construyendo imagen Docker..."
          docker build -t ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME}:${BUILD_NUMBER} .
          docker build -t ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME}:latest .
        fi

  post_build:
    commands:
      - echo "üéØ Fase post-construcci√≥n iniciada"

      # Verificaci√≥n de cobertura de pruebas
      - |
        if [ -f "coverage/lcov.info" ]; then
          COVERAGE=$(lcov --summary coverage/lcov.info 2>&1 | grep "lines" | cut -d' ' -f4 | cut -d'%' -f1)
          echo "üìä Cobertura de pruebas: ${COVERAGE}%"
          
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "‚ö†Ô∏è Cobertura de pruebas por debajo del umbral: ${COVERAGE}% < 80%"
          fi
        fi

      # Subir imagen Docker (si es necesario)
      - |
        if [ -f "Dockerfile" ]; then
          echo "üö¢ Subiendo imagen Docker..."
          aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com
          docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME}:${BUILD_NUMBER}
          docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME}:latest
        fi

      # Preparar paquete de despliegue
      - echo "üéÅ Preparando paquete de despliegue..."
      - cp build-info.json dist/
      - tar -czf deployment-package.tar.gz -C dist .

      # Informe de construcci√≥n
      - |
        echo "üìä Informe de Construcci√≥n" > build-report.txt
        echo "===============" >> build-report.txt
        echo "N√∫mero de Construcci√≥n: $BUILD_NUMBER" >> build-report.txt
        echo "Entorno: $ENVIRONMENT" >> build-report.txt
        echo "Commit: $COMMIT_SHA" >> build-report.txt
        echo "Tama√±o del Paquete: ${BUNDLE_SIZE}KB" >> build-report.txt
        echo "Cantidad de Activos: $ASSET_COUNT" >> build-report.txt
        if [ -n "$COVERAGE" ]; then
          echo "Cobertura de Pruebas: ${COVERAGE}%" >> build-report.txt
        fi
        echo "Tiempo de Construcci√≥n: $(date)" >> build-report.txt

      - |
        if [ $CODEBUILD_BUILD_SUCCEEDING -eq 1 ]; then
          echo "‚úÖ Construcci√≥n completada exitosamente"
        else
          echo "‚ùå Construcci√≥n fallida"
          exit 1
        fi

artifacts:
  files: 
    - "**/*"
  base-directory: dist
  name: build-$BUILD_NUMBER

secondary-artifacts:
  BuildReport:
    files:
      - build-report.txt
      - build-info.json
      - test-results.xml
      - sbom.spdx.json
    name: build-artifacts-$BUILD_NUMBER

  Coverage:
    files:
      - "coverage/**/*"
    name: coverage-$BUILD_NUMBER

reports:
  unit-tests:
    files:
      - "test-results.xml"
    file-format: "JUNITXML"

coverage-reports:
  coverage-reports:
    files:
      - "coverage/lcov.info"
    file-format: "CLOVERXML"

cache:
  paths:
    - "node_modules/**/*"
    - ".pnpm-store/**/*"
    - "/root/.cache/pip/**/*"
```

#### 2. Configuraciones de Construcci√≥n Espec√≠ficas del Entorno

```terraform
# Proyecto CodeBuild - Configuraci√≥n espec√≠fica del entorno
resource "aws_codebuild_project" "build" {
  for_each = var.environments

  name          = "${var.project_name}-build-${each.key}"
  description   = "Proyecto de construcci√≥n para el entorno ${each.key}"
  service_role  = aws_iam_role.codebuild_role.arn

  artifacts {
    type = "CODEPIPELINE"
  }

  environment {
    compute_type                = each.value.compute_type
    image                      = "aws/codebuild/standard:7.0"
    type                       = "LINUX_CONTAINER"
    image_pull_credentials_type = "CODEBUILD"
    privileged_mode            = true

    dynamic "environment_variable" {
      for_each = merge(
        var.common_env_vars,
        each.value.env_vars,
        {
          ENVIRONMENT = each.key
          BUILD_TARGET = each.value.build_target
          API_ENDPOINT = each.value.api_endpoint
        }
      )
      content {
        name  = environment_variable.key
        value = environment_variable.value
      }
    }

    # Variables de entorno sensibles
    dynamic "environment_variable" {
      for_each = each.value.secret_env_vars
      content {
        name  = environment_variable.key
        value = environment_variable.value
        type  = "PARAMETER_STORE"
      }
    }
  }

  source {
    type = "CODEPIPELINE"
    buildspec = templatefile("${path.module}/buildspec/${each.value.buildspec_file}", {
      environment = each.key
      node_version = each.value.node_version
      build_commands = each.value.build_commands
    })
  }

  vpc_config {
    vpc_id = each.value.vpc_id
    subnets = each.value.subnet_ids
    security_group_ids = [aws_security_group.codebuild[each.key].id]
  }

  logs_config {
    cloudwatch_logs {
      group_name  = aws_cloudwatch_log_group.codebuild[each.key].name
      stream_name = "build-log"
    }

    s3_logs {
      status   = "ENABLED"
      location = "${aws_s3_bucket.build_logs.bucket}/build-logs/${each.key}"
    }
  }

  tags = merge(var.tags, {
    Environment = each.key
    Purpose     = "Build"
  })
}

# Variables de configuraci√≥n de entorno
variable "environments" {
  description = "Configuraciones espec√≠ficas del entorno"
  type = map(object({
    compute_type     = string
    build_target     = string
    api_endpoint     = string
    node_version     = string
    buildspec_file   = string
    vpc_id          = string
    subnet_ids      = list(string)
    env_vars        = map(string)
    secret_env_vars = map(string)
    build_commands  = list(string)
  }))

  default = {
    development = {
      compute_type     = "BUILD_GENERAL1_SMALL"
      build_target     = "development"
      api_endpoint     = "https://api-dev.myapp.com"
      node_version     = "18"
      buildspec_file   = "development.yml"
      vpc_id          = "vpc-dev123"
      subnet_ids      = ["subnet-dev1", "subnet-dev2"]
      env_vars = {
        DEBUG_MODE = "true"
        LOG_LEVEL  = "debug"
      }
      secret_env_vars = {
        DEV_API_KEY = "/myapp/dev/api-key"
      }
      build_commands = [
        "npm run build:dev",
        "npm run test:unit"
      ]
    }

    staging = {
      compute_type     = "BUILD_GENERAL1_MEDIUM"
      build_target     = "staging"
      api_endpoint     = "https://api-staging.myapp.com"
      node_version     = "18"
      buildspec_file   = "staging.yml"
      vpc_id          = "vpc-staging123"
      subnet_ids      = ["subnet-staging1", "subnet-staging2"]
      env_vars = {
        DEBUG_MODE = "false"
        LOG_LEVEL  = "info"
      }
      secret_env_vars = {
        STAGING_API_KEY = "/myapp/staging/api-key"
      }
      build_commands = [
        "npm run build:staging",
        "npm run test:unit",
        "npm run test:integration"
      ]
    }

    production = {
      compute_type     = "BUILD_GENERAL1_LARGE"
      build_target     = "production"
      api_endpoint     = "https://api.myapp.com"
      node_version     = "18"
      buildspec_file   = "production.yml"
      vpc_id          = "vpc-prod123"
      subnet_ids      = ["subnet-prod1", "subnet-prod2"]
      env_vars = {
        DEBUG_MODE = "false"
        LOG_LEVEL  = "warn"
        OPTIMIZE   = "true"
      }
      secret_env_vars = {
        PROD_API_KEY    = "/myapp/production/api-key"
        SENTRY_DSN      = "/myapp/production/sentry-dsn"
        ANALYTICS_KEY   = "/myapp/production/analytics-key"
      }
      build_commands = [
        "npm run build:production",
        "npm run test:unit",
        "npm run test:integration",
        "npm run test:e2e"
      ]
    }
  }
}
```

## Implementaci√≥n de la Puerta de Revisi√≥n de Negocio

Finalmente, en un entorno empresarial, el despliegue en producci√≥n debe pasar por una rigurosa **revisi√≥n de confirmaci√≥n de l√≥gica de negocio** antes de que pueda incorporarse al lanzamiento oficial del producto de la empresa. Ahora implementaremos un mecanismo de revisi√≥n que combina una **Puerta de Revisi√≥n por Pares**, una **Puerta de Revisi√≥n de Negocio** y una **Puerta de Revisi√≥n de Calidad**.

```mermaid
graph TD
    subgraph "Revisi√≥n Inteligente y Notificaci√≥n"
        A[Solicitud de Despliegue Activada] --> B{Analizar Riesgo y Tipo de Cambio}
        B --> C{Determinar Ruta de Aprobaci√≥n}
        C --> D[Crear Registro de Aprobaci√≥n<br/>usando DynamoDB]
        D --> E[Enviar Notificaciones Multi-canal<br/>Slack y Correo Electr√≥nico]
    end

    subgraph "Puertas de Aprobaci√≥n Multi-Nivel"
        E --> F{Revisi√≥n T√©cnica Requerida?}
        F -->|S√≠| G[Revisi√≥n del L√≠der T√©cnico<br/>v√≠a Slack/UI]
        F -->|No| J{Revisi√≥n de Negocio Requerida?}
        G --> H{Aprobado?}
        H -->|No| Z[Aprobaci√≥n Fallida]
        H -->|S√≠| J
        J -->|S√≠| K[Revisi√≥n del Gerente de Producto<br/>v√≠a Slack/UI]
        J -->|No| P{Revisi√≥n de Seguridad Requerida?}
        K --> L{Aprobado?}
        L -->|No| Z
        L -->|S√≠| P
        P -->|S√≠| Q[Revisi√≥n del Equipo de Seguridad<br/>v√≠a Slack/UI]
        P -->|No| T[Todas las Aprobaciones Completas]

        Q --> R{Aprobado?}
        R -->|No| Z
        R -->|S√≠| T
    end

    subgraph "Autorizaci√≥n y Ejecuci√≥n Final"
        T --> U[Autorizaci√≥n Final de Despliegue]
        U --> V[‚úÖ Activar Despliegue en Producci√≥n]
        Z --> W[‚ùå Notificar Fallo y Raz√≥n]
    end

    style A fill:#e3f2fd,stroke:#333,stroke-width:2px
    style V fill:#e8f5e9,stroke:#333,stroke-width:2px
    style W fill:#ffebee,stroke:#333,stroke-width:2px
    style Z fill:#ffebee,stroke:#333,stroke-width:2px
```

### 1. Proceso de Aprobaci√≥n Multi-nivel

```yaml
# .github/workflows/approval-workflow.yml
name: "Aprobaci√≥n de Despliegue en Producci√≥n"

on:
  workflow_call:
    inputs:
      deployment-version:
        required: true
        type: string
      staging-url:
        required: true
        type: string

jobs:
  # Primera capa: Revisi√≥n T√©cnica
  technical-review:
    name: "Revisi√≥n T√©cnica"
    runs-on: ubuntu-latest

    environment:
      name: technical-approval

    steps:
      - name: Validaci√≥n de lista de verificaci√≥n t√©cnica
        run: |
          echo "üîç Lista de Verificaci√≥n T√©cnica"
          echo "=============================="
          echo "üì¶ Versi√≥n: ${{ inputs.deployment-version }}"
          echo "üåê URL de Staging: ${{ inputs.staging-url }}"
          echo ""
          echo "Por favor, verifique:"
          echo "‚úì Todas las pruebas pasan"
          echo "‚úì Revisi√≥n de c√≥digo completada"
          echo "‚úì Escaneo de seguridad aprobado"
          echo "‚úì Puntos de referencia de rendimiento alcanzados"
          echo "‚úì Documentaci√≥n actualizada"
          echo ""
          echo "Aprobado por: L√≠der T√©cnico"
```

### 2. Reglas de Aprobaci√≥n Inteligentes

```yaml
# .github/workflows/smart-approval.yml
name: "L√≥gica de Aprobaci√≥n Inteligente"

on:
  workflow_call:
    inputs:
      change-type:
        required: true
        type: string
      risk-level:
        required: true
        type: string
      affected-components:
        required: true
        type: string

jobs:
  determine-approval-path:
    name: "Determinar Requisitos de Aprobaci√≥n"
    runs-on: ubuntu-latest

    outputs:
      requires-technical: ${{ steps.approval-logic.outputs.requires-technical }}
      requires-business: ${{ steps.approval-logic.outputs.requires-business }}
      requires-security: ${{ steps.approval-logic.outputs.requires-security }}
      requires-emergency: ${{ steps.approval-logic.outputs.requires-emergency }}

    steps:
      - name: Analizar requisitos de cambio
        id: approval-logic
        run: |
          CHANGE_TYPE="${{ inputs.change-type }}"
          RISK_LEVEL="${{ inputs.risk-level }}"
          AFFECTED_COMPONENTS="${{ inputs.affected-components }}"

          # Requisitos de aprobaci√≥n predeterminados
          REQUIRES_TECHNICAL="true"
          REQUIRES_BUSINESS="false"
          REQUIRES_SECURITY="false"
          REQUIRES_EMERGENCY="false"

          echo "üìä Analizando requisitos de cambio..."
          echo "Tipo de Cambio: $CHANGE_TYPE"
          echo "Nivel de Riesgo: $RISK_LEVEL"
          echo "Componentes Afectados: $AFFECTED_COMPONENTS"

          # Juicio del nivel de riesgo
          case "$RISK_LEVEL" in
            "low")
              REQUIRES_BUSINESS="false"
              REQUIRES_SECURITY="false"
              ;;;
            "medium")
              REQUIRES_BUSINESS="true"
              REQUIRES_SECURITY="false"
              ;;;
            "high"|"critical")
              REQUIRES_BUSINESS="true"
              REQUIRES_SECURITY="true"
              ;;;
          esac

          # Juicio del tipo de cambio
          case "$CHANGE_TYPE" in
            "hotfix"|"emergency")
              REQUIRES_EMERGENCY="true"
              REQUIRES_BUSINESS="false"
              REQUIRES_SECURITY="false"
              ;;;
            "security-patch")
              REQUIRES_SECURITY="true"
              ;;;
            "feature")
              REQUIRES_BUSINESS="true"
              ;;;
          esac

          # Juicio de componentes afectados
          if [[ "$AFFECTED_COMPONENTS" == *"authentication"* ]] || \
             [[ "$AFFECTED_COMPONENTS" == *"payment"* ]] || \
             [[ "$AFFECTED_COMPONENTS" == *"user-data"* ]]; then
            REQUIRES_SECURITY="true"
          fi

          if [[ "$AFFECTED_COMPONENTS" == *"database"* ]] || \
             [[ "$AFFECTED_COMPONENTS" == *"infrastructure"* ]]; then
            REQUIRES_SECURITY="true"
            REQUIRES_BUSINESS="true"
          fi

          # Resultados de salida
          echo "requires-technical=$REQUIRES_TECHNICAL" >> $GITHUB_OUTPUT
          echo "requires-business=$REQUIRES_BUSINESS" >> $GITHUB_OUTPUT
          echo "requires-security=$REQUIRES_SECURITY" >> $GITHUB_OUTPUT
          echo "requires-emergency=$REQUIRES_EMERGENCY" >> $GITHUB_OUTPUT

          echo ""
          echo "üìã Requisitos de Aprobaci√≥n:"
          echo "Revisi√≥n T√©cnica: $REQUIRES_TECHNICAL"
          echo "Revisi√≥n de Negocio: $REQUIRES_BUSINESS"
          echo "Revisi√≥n de Seguridad: $REQUIRES_SECURITY"
          echo "Proceso de Emergencia: $REQUIRES_EMERGENCY"

  conditional-approvals:
    name: "Ejecutar Aprobaciones Requeridas"
    needs: determine-approval-path
    uses: ./.github/workflows/conditional-approval.yml
    with:
      requires-technical: ${{ needs.determine-approval-path.outputs.requires-technical }}
      requires-business: ${{ needs.determine-approval-path.outputs.requires-business }}
      requires-security: ${{ needs.determine-approval-path.outputs.requires-security }}
      requires-emergency: ${{ needs.determine-approval-path.outputs.requires-emergency }}
```

### 3. Notificaci√≥n y Seguimiento de Aprobaciones

```python
# scripts/approval-notification.py
import json
import boto3
import requests
from datetime import datetime, timedelta

class ApprovalNotificationManager:
    def __init__(self):
        self.sns = boto3.client('sns')
        self.dynamodb = boto3.resource('dynamodb')
        self.approval_table = self.dynamodb.Table('approval-tracking')

    def create_approval_request(self, deployment_info):
        """Crear una solicitud de aprobaci√≥n"""
        approval_id = f"approval-${deployment_info['build_number']}-${int(datetime.now().timestamp())}"

        approval_record = {
            'approval_id': approval_id,
            'deployment_version': deployment_info['version'],
            'staging_url': deployment_info['staging_url'],
            'requester': deployment_info['requester'],
            'created_at': datetime.now().isoformat(),
            'expires_at': (datetime.now() + timedelta(hours=24)).isoformat(),
            'status': 'pending',
            'required_approvals': deployment_info['required_approvals'],
            'completed_approvals': [],
            'change_summary': deployment_info['change_summary']
        }

        # Guardar en DynamoDB
        self.approval_table.put_item(Item=approval_record)

        # Enviar notificaciones
        self.send_approval_notifications(approval_record)

        return approval_id

    def send_approval_notifications(self, approval_record):
        """Enviar notificaciones de aprobaci√≥n"""

        # Notificaci√≥n por correo electr√≥nico
        self.send_email_notification(approval_record)

        # Notificaci√≥n de Slack
        self.send_slack_notification(approval_record)

        # Notificaci√≥n de Teams
        self.send_teams_notification(approval_record)

    def send_slack_notification(self, approval_record):
        """Enviar notificaci√≥n de Slack"""
        webhook_url = os.environ.get('SLACK_WEBHOOK_URL')

        required_approvals = approval_record['required_approvals']
        approval_buttons = []

        for approval_type in required_approvals:
            approval_buttons.append({
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": f"Aprobar {approval_type.title()}"
                },
                "action_id": f"approve_{approval_type}",
                "value": approval_record['approval_id'],
                "style": "primary"
            })

        message = {
            "blocks": [
                {
                    "type": "header",
                    "text": {
                        "type": "plain_text",
                        "text": "üöÄ Aprobaci√≥n de Despliegue a Producci√≥n Requerida"
                    }
                },
                {
                    "type": "section",
                    "fields": [
                        {
                            "type": "mrkdwn",
                            "text": f"*Versi√≥n:* {approval_record['deployment_version']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Solicitante:* {approval_record['requester']}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*URL de Staging:* <{approval_record['staging_url']}|Ver Staging>"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Expira:* {approval_record['expires_at']}"
                        }
                    ]
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*Resumen del Cambio:*
{approval_record['change_summary']}"
                    }
                },
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": f"*Aprobaciones Requeridas:* {', '.join(required_approvals)}"
                    }
                },
                {
                    "type": "actions",
                    "elements": approval_buttons + [
                        {
                            "type": "button",
                            "text": {
                                "type": "plain_text",
                                "text": "Rechazar"
                            },
                            "action_id": "reject_deployment",
                            "value": approval_record['approval_id'],
                            "style": "danger"
                        }
                    ]
                }
            ]
        }

        response = requests.post(webhook_url, json=message)
        return response.status_code == 200

    def process_approval_response(self, approval_id, approval_type, approver, decision):
        """Procesar respuesta de aprobaci√≥n"""

        # Obtener registro de aprobaci√≥n
        response = self.approval_table.get_item(Key={'approval_id': approval_id})
        approval_record = response.get('Item')

        if not approval_record:
            return {'error': 'Registro de aprobaci√≥n no encontrado'}

        if approval_record['status'] != 'pending':
            return {'error': 'Aprobaci√≥n ya completada o expirada'}

        # Actualizar estado de aprobaci√≥n
        if decision == 'approve':
            approval_record['completed_approvals'].append({
                'type': approval_type,
                'approver': approver,
                'timestamp': datetime.now().isoformat(),
                'decision': 'approved'
            })
        else:
            approval_record['status'] = 'rejected'
            approval_record['rejected_by'] = approver
            approval_record['rejected_at'] = datetime.now().isoformat()

        # Verificar si todas las aprobaciones necesarias est√°n completas
        required_approvals = set(approval_record['required_approvals'])
        completed_approvals = set([a['type'] for a in approval_record['completed_approvals']])

        if decision == 'approve' and required_approvals.issubset(completed_approvals):
            approval_record['status'] = 'approved'
            approval_record['approved_at'] = datetime.now().isoformat()

            # Activar proceso de despliegue
            self.trigger_deployment(approval_record)

        # Actualizar registro de la base de datos
        self.approval_table.put_item(Item=approval_record)

        # Enviar notificaci√≥n de actualizaci√≥n de estado
        self.send_status_update(approval_record, approval_type, approver, decision)

        return {'status': approval_record['status']}

    def trigger_deployment(self, approval_record):
        """Activar despliegue a producci√≥n"""

        # Activar flujo de trabajo de despliegue a trav√©s de la API de GitHub
        github_token = os.environ.get('GITHUB_TOKEN')
        repo_owner = os.environ.get('GITHUB_REPO_OWNER')
        repo_name = os.environ.get('GITHUB_REPO_NAME')

        headers = {
            'Authorization': f'Bearer {github_token}',
            'Accept': 'application/vnd.github.v3+json'
        }

        workflow_data = {
            'ref': 'main',
            'inputs': {
                'deployment_version': approval_record['deployment_version'],
                'approval_id': approval_record['approval_id'],
                'approved_by': ', '.join([a['approver'] for a in approval_record['completed_approvals']])
            }
        }

        url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/actions/workflows/production-deploy.yml/dispatches"
        response = requests.post(url, json=workflow_data, headers=headers)

        return response.status_code == 204

    def send_status_update(self, approval_record, approval_type, approver, decision):
        """Enviar notificaci√≥n de actualizaci√≥n de estado"""

        status_emoji = "‚úÖ" if decision == "approve" else "‚ùå"
        status_text = "aprobado" if decision == "approve" else "rechazado"

        if approval_record['status'] == 'approved':
            message = f"üöÄ ¬°Despliegue aprobado y activado!\n"
            message += f"Versi√≥n: {approval_record['deployment_version']}\n"
            message += f"Todas las aprobaciones requeridas completadas."
        elif approval_record['status'] == 'rejected':
            message = f"‚ùå Despliegue rechazado por {approver}\n"
            message += f"Versi√≥n: {approval_record['deployment_version']}\n"
            message += f"Raz√≥n: Aprobaci√≥n de {approval_type} denegada."
        else:
            remaining_approvals = set(approval_record['required_approvals']) - set([a['type'] for a in approval_record['completed_approvals']])
            message = f"{status_emoji} {approval_type.title()} {status_text} por {approver}\n"
            message += f"Versi√≥n: {approval_record['deployment_version']}\n"
            message += f"Aprobaciones restantes necesarias: {', '.join(remaining_approvals)}"

        # Enviar actualizaci√≥n de Slack
        webhook_url = os.environ.get('SLACK_WEBHOOK_URL')
        requests.post(webhook_url, json={"text": message})

# Funci√≥n manejadora de Lambda
def lambda_handler(event, context):
    manager = ApprovalNotificationManager()

    if event.get('action') == 'create_approval':
        approval_id = manager.create_approval_request(event['deployment_info'])
        return {'approval_id': approval_id}

    elif event.get('action') == 'process_response':
        result = manager.process_approval_response(
            event['approval_id'],
            event['approval_type'],
            event['approver'],
            event['decision']
        )
        return result

    else:
        return {'error': 'Acci√≥n desconocida'}
```

## Construyendo un Pipeline de Entrega de Software Moderno

La automatizaci√≥n completa de CI/CD trae cambios fundamentales al desarrollo de software moderno. Partimos de los puntos d√©biles del despliegue manual tradicional y profundizamos en la construcci√≥n de un pipeline de automatizaci√≥n completo, con un enfoque especial en los requisitos a nivel empresarial:

### Reafirmando los Valores Fundamentales

**Transformaci√≥n Tecnol√≥gica**:

- **Gesti√≥n de la Fragmentaci√≥n de Tareas**: Dividir razonablemente las tareas para mejorar la eficiencia de ejecuci√≥n y la mantenibilidad.
- **Gesti√≥n del Control de Versiones de Tareas**: Controlar las versiones del proceso de CI/CD para asegurar la trazabilidad.
- **Gesti√≥n de la Abstracci√≥n de Par√°metros**: Separar las configuraciones de entorno para soportar el despliegue en m√∫ltiples entornos.
- **Puerta de Revisi√≥n de Negocio**: Integrar la revisi√≥n manual en la automatizaci√≥n para equilibrar la eficiencia y el riesgo.

**Impacto Organizacional**:

- **Equilibrio entre Eficiencia y Calidad**: La automatizaci√≥n mejora la eficiencia, mientras que los mecanismos de revisi√≥n aseguran la calidad.
- **Agilidad con Riesgo Controlado**: Un equilibrio entre la entrega r√°pida y el control de riesgos.
- **Colaboraci√≥n en Equipo Optimizada**: Procesos claros y divisi√≥n de responsabilidades.
- **Cultura de Mejora Continua**: Optimizaci√≥n de procesos basada en datos.

### Factores Clave de √âxito para la Implementaci√≥n

#### 1. Estrategia de Automatizaci√≥n Incremental

- Comenzar a automatizar con tareas sencillas.
- Aumentar gradualmente la complejidad y la cobertura.
- Establecer mecanismos de monitoreo y alerta.
- Optimizar continuamente la eficiencia del proceso.

#### 2. Mecanismo de Revisi√≥n Inteligente

- Revisi√≥n din√°mica basada en el nivel de riesgo.
- Gesti√≥n automatizada del proceso de revisi√≥n.
- Notificaci√≥n y seguimiento multicanal.
- Registro completo del historial de revisiones.

#### 3. Capacidades de Integraci√≥n a Nivel Empresarial

- Integraci√≥n perfecta con los sistemas existentes.
- Soporte para entornos multi-nube.
- Consideraci√≥n de la seguridad y el cumplimiento.
- Dise√±o arquitect√≥nico escalable.

### La Evoluci√≥n del Despliegue Manual a la Entrega Inteligente

**Fase 1: Despliegue Manual** ‚Üí **Fase 2: Pipeline Automatizado** ‚Üí **Fase 3: Entrega Inteligente**

Ahora estamos entrando en la tercera fase, caracterizada por:

- **Decisiones Inteligentes**: Decisiones automatizadas basadas en datos hist√≥ricos y monitoreo en tiempo real.
- **Procesos Adaptativos**: Ajuste autom√°tico basado en las caracter√≠sticas del proyecto y los h√°bitos del equipo.
- **Mantenimiento Predictivo**: Identificaci√≥n y prevenci√≥n proactiva de problemas potenciales.
- **Aprendizaje Continuo**: Aprender de cada despliegue y optimizar el proceso.

### Perspectivas Futuras: CI/CD Impulsado por IA

- **Selecci√≥n Inteligente de Pruebas**: La IA analiza los cambios de c√≥digo y selecciona inteligentemente las estrategias de prueba.
- **Diagn√≥stico Automatizado de Problemas**: Los modelos de aprendizaje autom√°tico analizan autom√°ticamente las razones de los fallos.
- **Despliegue Predictivo**: Optimizaci√≥n del momento del despliegue basada en la evaluaci√≥n de riesgos.
- **Gesti√≥n Inteligente de Recursos**: Ajustar din√°micamente los recursos inform√°ticos para optimizar los costos.

**CI/CD nos permite ser no solo "operadores que despliegan c√≥digo", sino "arquitectos que dise√±an sistemas de entrega inteligentes."**

Este es el verdadero valor de la automatizaci√≥n completa de CI/CD: no solo hace que la entrega de software sea confiable, r√°pida y predecible, sino que, lo que es m√°s importante, establece un sistema inteligente capaz de aprendizaje y mejora continuos. En este entorno tecnol√≥gico que cambia r√°pidamente, dominar las pr√°cticas modernas de CI/CD se ha convertido en una competencia central para cada equipo de software.

A trav√©s de un pipeline de CI/CD completo, logramos la automatizaci√≥n total desde la subida de c√≥digo hasta el despliegue en producci√≥n, manteniendo la revisi√≥n manual necesaria y el control de riesgos. Este equilibrio nos permite disfrutar de las ganancias de eficiencia de la automatizaci√≥n al tiempo que garantizamos la seguridad y estabilidad del negocio. Este es el n√∫cleo de la ingenier√≠a de software moderna: **la fusi√≥n perfecta de tecnolog√≠a y negocio**.